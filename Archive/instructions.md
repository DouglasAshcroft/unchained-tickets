# Unchained – Project Overview & Developer Guide

**Companion Note:** For a condensed AI-focused checklist, open `AI_instructions.md`.

## Overview

### Project Goals & Problem Statement
Unchained is a decentralized ticketing platform built to disrupt the monopoly of traditional event ticketing (e.g. combating Ticketmaster-like control). It leverages blockchain technology to eliminate counterfeit tickets, prevent scalping, reward loyal fans, and empower the community of artists and attendees[1]. In today’s ticketing industry, users face rampant fraud and price gouging by resellers; artists and venues lose control over secondary sales. Unchained addresses these issues by ensuring fairness, transparency, and fan rewards through smart contracts[2]. Its mission-driven approach aims to create a transparent, fan-first ecosystem free from monopolistic control[3].

### Core Functionality
- NFT Ticketing with Royalties: Event tickets are minted as ERC-721 NFTs, optionally with ERC-2981 royalty standards so that organizers or artists get a cut from any resale[4]. Smart contracts automatically prevent scalping by capping resale prices or enforcing royalties on secondary transfers[4]. This ensures tickets cannot be easily flipped for profit without benefiting the content creators.
- Authenticity & Anti-Fraud: Because each ticket is a unique token on the blockchain, it’s impossible to counterfeit. Venues can easily verify on-chain that a ticket is genuine, eliminating fake tickets and fraud at entry[1].
- Collectible Ticket Stubs: After an event, the NFT ticket serves as a digital collectible (souvenir) for the fan[5]. Fans can keep or trade these NFT ticket stubs, which might unlock future perks. This builds a sense of community and rewards fandom beyond the event itself.
- Analytics & Dashboards: The platform provides dashboards for venues and artists[6]. Organizers can see real-time data on ticket ownership, transfers, and attendance. This actionable analytics information (e.g. how many tickets were resold, fan demographics, etc.) helps them make informed decisions for future events.
- Fan Loyalty & Rewards: A built-in loyalty system rewards fans for attending events and holding tickets[6]. For example, fans might earn tokens or exclusive access to merchandise and presales after attending multiple events. This encourages genuine fans to participate and remain engaged.
- Event Discovery & Community: Users can search for events, venues, or artists via a discovery interface with fuzzy search[7]. A landing page (“Join The Resistance”) acts as a waitlist/signup funnel for early adopters[8], reflecting the project’s punk/activist branding. This helps build a community and user base before full launch.

Overall, Unchained’s target audience includes music fans (who want authentic tickets and collectible experiences), artists (who seek fair royalties and direct fan engagement), and venues (needing fraud prevention and better analytics)[9]. By aligning the interests of these groups, the platform strives to create a fairer, more transparent ticketing ecosystem powered by blockchain.

## Tech Stack
This project uses a modern web and blockchain stack. Below is an overview of all major technologies, libraries, and frameworks used (with versions where applicable):
- Frontend: React (v18+) single-page application, bootstrapped with Vite for fast builds and dev server[10]. The UI is styled using Tailwind CSS (v3) along with custom CSS modules for unique design elements. Routing is handled by React Router (v6+).
- Backend: Node.js (v18 LTS) powers any server-side logic. The app uses a lightweight Express (v4) server for API endpoints, which in production is deployed as serverless functions on Vercel. This means each API route runs as a standalone cloud function, enabling scalable on-demand backend execution.
- Blockchain & Smart Contracts: The platform is built on the Ethereum Virtual Machine (EVM) ecosystem, specifically targeting the Polygon network (a cost-effective Ethereum L2) for deploying smart contracts[10]. Smart contracts are written in Solidity and managed using Hardhat (2.x) during development[11]. We also leverage Thirdweb SDK/tools for quick contract deployment and management as needed[12]. The NFT ticket contract implements standards like ERC-721 for tokens and ERC-2981 for royalties.
- Web3 Integration: On the client side, we use the ethers.js library and Wagmi React hooks (v0.x or v1) for blockchain interactions. RainbowKit and the Coinbase Wallet SDK are integrated to provide a smooth wallet connection UI. This allows users to connect with MetaMask, Coinbase Wallet, or others to purchase and hold their NFT tickets. The Coinbase Onchain Kit is explored as well – it offers pre-built components and utilities for building on-chain user experiences (particularly useful if integrating with Coinbase’s Base network or account abstraction features).
- Storage: Event and ticket metadata (images, descriptions) are stored off-chain using decentralized storage. We utilize NFT.Storage (an IPFS pinning service) to store media and JSON metadata on IPFS (InterPlanetary File System). This ensures that ticket details and artwork remain publicly accessible and tamper-proof.
- Search: For client-side searching and fuzzy matching through events, artists, or venues, we include Fuse.js. This lightweight library enables substring and approximate text matching to improve the user’s ability to find events (e.g., searching by partial artist name or venue).
- Hosting & Deployment: The application is hosted on Vercel, which provides an all-in-one platform for static frontends and API functions. Vercel is connected to our Git repository for continuous deployment; every push to main triggers a rebuild and redeploy. (See Deployment section for details.)
- Developer Tooling (AI Assistants): To boost productivity, the team leverages AI coding assistants in the development workflow. Notably, we use Anthropic’s Claude Code (powered by the Claude Sonnet 4.5 model) and OpenAI’s Codex CLI:
  - Claude Code (Sonnet 4.5): An advanced AI pair-programming assistant by Anthropic. Claude Code can understand the entire project repository context and provide intelligent code suggestions, refactorings, and even generate new files based on natural language instructions[13]. Sonnet 4.5 is the underlying model that grants Claude Code extended autonomous coding capabilities, allowing it to handle long coding sessions and complex tasks with improved reasoning[14]. In practice, we use Claude in the CLI/IDE to help write boilerplate, find bugs, and accelerate development.
  - OpenAI Codex CLI: An AI coding agent from OpenAI that runs locally in the terminal[15]. Codex CLI can interpret commands or prompts and directly modify code or execute tasks. It’s essentially an AI that can take shell instructions and code context to assist with implementations. We use Codex for on-demand code generation and to automate repetitive coding tasks through the command line.

By combining this tech stack, Unchained delivers a full-stack DApp (Decentralized Application) experience: a React/Tailwind UI, a Node/Vercel serverless backend, and smart contracts on Polygon, all integrated seamlessly. The inclusion of AI coding tools (Claude and Codex) is also an innovative part of our development process, enabling faster and smarter coding.

## Project Structure
The repository follows a structured layout to organize source code and assets. Below is an outline of the core project folders and files, with explanations for each:
- src/assets/ – Contains static assets like images, icons, and texture files used in the app. For example, background images or logo files referenced in components would reside here.
- src/components/ – Reusable UI components for the React frontend. These are usually small, self-contained pieces of the interface (buttons, cards, navigation items, etc.) that can be composed to build pages. For instance, EventCard.jsx displays a summary of an event (with image, title, date) and is used across different pages.
- src/pages/ – Page-level components representing different screens or routes in the application. Each page might import many components. Examples include Home.jsx, EventDetail.jsx, or TicketView.jsx. Pages correspond to routes in the React Router configuration.
- src/utils/ – Utility modules and helper functions. These contain non-React logic that can be reused across the app. For example, a slugify.js for creating URL-friendly strings from event names[16], an openGoogleMaps.js to abstract opening external map links, or other data processing helpers. Placing these in utils keeps components cleaner and promotes reuse.
- src/styles/ – All styling files (CSS) are organized here. We use a combination of Tailwind CSS utility classes and custom CSS. The styles folder is further subdivided for maintainability:
  - styles/base/ – Global base styles such as resets (e.g. _reset.css), typography defaults (_typography.css), and general global rules (_globals.css for things like box-sizing, element defaults)[17]. These are loaded first to establish a baseline.
  - styles/tokens/ – Design tokens and variables, e.g. _colors.css defining the central color palette, _spacing.css for spacing scale (margin/padding sizes), _typescale.css for font sizes and line-heights[18]. By defining these in one place, we ensure consistency (the values here correspond to the brand style guide).
  - styles/components/ – Component-specific CSS classes. For example, button.css contains styles for the custom button styles used in the app, input.css for form elements, card.css for card components like event cards[19]. These are imported by the corresponding JSX components or by the main CSS.
  - styles/layout/ – Layout helpers, such as grid.css (common grid or flexbox utilities) and containers.css (max-widths for containers, layout structure)[20].
  - styles/index.css – The main stylesheet that imports all the other CSS files in the correct order[21]. This is the file ultimately loaded by the app to apply all styles.
- src/App.jsx – The root React component that defines the overall application structure and routing. This typically includes the Router setup (mapping URL paths to the components in pages/), as well as any global context providers (for theme, authentication, API data, etc.). It can be thought of as the “controller” of the frontend. [22]
- src/main.jsx – The entry point for the React application. This is where we mount the App component onto the DOM. Vite uses this as the bootstrap file. It usually contains something like ReactDOM.createRoot(...).render(<App />). (If we were using TypeScript or advanced configurations, this is also where HMR and strict mode might be set up.)[22]
- (Potential) src/api/ – In a full-stack project on Vercel, we might have an api/ directory for serverless function files (e.g., src/api/checkout.js for a ticket purchase endpoint). In this project, API calls for event data might instead be handled client-side (for example, fetching from SerpAPI directly in the frontend), so an api/ folder may not be present. If future backend functions are needed (like a custom endpoint), this is where they would live, and Vercel would deploy them automatically.
- Other config files – The project root includes typical configuration files: package.json (npm dependencies and scripts), possibly .eslintrc.json or .prettierrc (for linting/format rules), and smart contract directories if any (e.g., a contracts/ folder or Hardhat config if Solidity code is present). There’s also a README.md which provides high-level info (much of which is reflected in this guide).

This structure groups related files together, making the project maintainable and scalable. For instance, all UI components are in one place, styles are centralized, and utilities are separated from React components. The layout shown above is drawn from the project’s architecture documentation[23][24], ensuring that anyone reading this guide or using an AI assistant on the repo has a clear map of where things are.

## Coding Standards
We adhere to consistent coding conventions and best practices to maintain code quality and readability. Below are the style guidelines, linting rules, and design patterns followed in the Unchained project:
- Code Style & Formatting: We use Prettier as an automated code formatter across the project. All code should be formatted with Prettier’s default conventions (2-space indentation, semicolons, quotes, etc.) on save or before commit. Prettier ensures that the entire codebase has a consistent style, automatically reprinting code in a unified format[25]. This eliminates debates over styling – developers can focus on logic, and the formatter takes care of spacing, line breaks, and so on. (Prettier is widely considered an industry-standard tool for JS formatting, and using it helps us follow common best practices out-of-the-box.) We also encourage using an editor integration for Prettier or a pre-commit hook, so that code is always formatted correctly.
- Linting & Best Practices: In addition to formatting, we enforce code quality via ESLint. The project is configured (or plans to be configured) with an ESLint setup – likely extending a well-known style guide such as Airbnb or using eslint:recommended with Prettier integration. The linter will catch common bugs or anti-patterns (unused variables, undefined variables, improper React hook usage, etc.). All team members (and AI assistants) should ensure code passes lint checks. For example, follow naming conventions: use camelCase for variables/functions, PascalCase for React components, and UPPER_SNAKE_CASE for constants. Prefer const and let over var, and use ES6+ syntax (arrow functions, spread operators, template strings) for cleaner, modern JavaScript.
- Project Patterns: We follow a component-driven architecture in React. That means keeping components focused and reusable. Functional components (with hooks) are used exclusively (no legacy class components). Related to that, React hooks are used for stateful logic and side effects – e.g., a custom hook useFuseSearch encapsulates search logic[26], and Context API is used for global state like events data (see APIContext usage in components). This pattern keeps view components (pages and UI elements) declarative and offloads data fetching or logic to hooks and context providers.
- UI/UX Consistency: All UI elements and styling follow the design system outlined in our Style Guide. Developers should use the predefined CSS classes (from styles/) and Tailwind utilities instead of arbitrary new styles, to maintain consistency. For example, use the color variables and spacing scales defined in styles/tokens/_colors.css and _spacing.css rather than hardcoding hex colors or pixel values. The “punk/underground” aesthetic (gritty textures, neon accents) described in the style guide should be reflected in the components – e.g., using the Resistance Red and Toxic Neon colors for call-to-action elements as specified. When in doubt, refer to Unchained Style Guide for visual guidelines on components like buttons, cards, etc. This ensures the app’s look stays unified.
- Accessibility: We prioritize building an accessible application. Follow ARIA and accessibility best practices: use semantic HTML elements where possible (e.g., <button> for clickable actions, <nav> for navigation regions), and add ARIA labels/roles for custom components. All interactive elements must be reachable via keyboard (tab navigation) and provide visual focus states. We also ensure sufficient color contrast in text and UI (meeting WCAG AA standards)[27]. For example, the design palette was chosen with contrast in mind and developers should not deviate in ways that reduce readability. Any image must have an alt attribute describing it (especially important if the image conveys info). By adhering to these, we make the app usable for as many people as possible.
- Git & Commit Conventions: (If applicable) We follow a conventional commit style or at least clear commit messages. When using the AI assistants for generating code, it’s still the developer’s job to summarize changes in commit messages for clarity. Feature branches and pull requests should be used for major features, with code reviews (even if AI-generated code) to maintain quality.
- Testing & QA: (Planned) Testing is crucial especially with AI-generated code. We intend to write unit tests (perhaps using Jest or Vitest) for critical functions like smart contract interactions or utility functions. Test files would mirror the structure (e.g., utils/slugify.test.js). Ensure new code is covered by tests where feasible. Even if not fully in place yet, developers should manually test features (e.g., actually attempt an NFT purchase in a test environment, or run through the ticket redemption flow) to validate that everything works as expected.

In summary, code contributors (human or AI) should produce clean, readable code that aligns with the established style. Prettier handles the micro-formatting, while developers must enforce logical consistency and project conventions. By following these standards, we ensure the codebase remains maintainable and coherent as the project grows.

## User Stories
To understand the platform’s features from an end-user perspective, here are key user stories categorized by user type (fan, artist/organizer, venue). These stories illustrate what each type of user can achieve with Unchained, and they reflect the platform’s core value propositions:
- As a Music Fan (Ticket Buyer): I want to discover upcoming events easily and buy authentic tickets with confidence. Using Unchained, I can search for events or artists and purchase a ticket as an NFT directly from the official source. This guarantees that my ticket is not counterfeit and I won’t be scammed at the door. After the event, I still hold the NFT as a digital collectible stub, which might grant me exclusive content or just serve as a memorable keepsake. I also enjoy loyalty rewards for using the platform – for example, being a repeat attendee could unlock special perks or early access to future tickets. (Target outcome: fans get legitimate tickets and added value like collectibles and rewards, addressing their desire for authentic access and a closer connection to the experience[28].)
- As an Avid Fan (Resale Participant): I want the ability to resell my ticket if I can’t attend, but in a fair way. On Unchained, if I list my NFT ticket for resale, the platform’s smart contract might enforce a price cap or automatically include a royalty. This means I can recoup my cost (or a modest profit) but cannot scalp the ticket at exorbitant prices, keeping things fair for other fans. I’m okay with this because it also means if I’m buying a resold ticket, I won’t have to pay an outrageous markup – the system protects me either way. Plus, any resale royalty might go to the artist or event organizer, supporting them rather than just profiteers.
- As an Event Organizer/Artist: I want control over my event’s ticketing and to ensure true fans get access. With Unchained, I can mint a fixed number of NFT tickets for my event and sell them directly to fans without middleman platforms taking a huge cut. I can set rules like “tickets cannot be resold above face value” or “I receive 10% of any resale via royalty.” This guarantees that scalpers cannot exploit my tickets, and if they do resell, I share in the upside[28]. I also get a dashboard that shows who my top fans are (e.g., someone who holds many of my event NFTs) and I can reward them with special NFTs or experiences. After the show, I know each ticket NFT’s holder – this opens up new marketing opportunities like airdropping a thank-you token or offering discount codes to those who attended. Essentially, I gain actionable insights and a direct relationship with my audience that wasn’t possible with traditional ticketing.
- As a Venue Manager: I need to ensure smooth entry and eliminate fraud at the gate. Using Unchained’s system, my team can scan a ticket’s QR code or wallet at entry and instantly verify on the blockchain that it’s a valid ticket that hasn’t been used before. This gives us confidence that no fake tickets will slip through[1], avoiding any confrontation with fans holding bogus tickets. The entry process becomes quicker and more secure. Additionally, I can see analytics on attendance: because each NFT ticket is traceable, I can know how many people transferred their tickets, how many checked in, etc. Over time, this helps with planning (for instance, identifying that a certain percentage of tickets always get resold might inform pricing or security measures). The data and fraud prevention together provide a better experience for both staff and attendees[9].
- As a New User (Waitlist Member): I am interested in the concept and want to join the platform early. I can sign up on the “Join The Resistance” waitlist page. As a member of the waitlist or early adopter, I might receive updates, beta access, or even an NFT badge that labels me as part of the founding community. This makes me feel involved in the movement to change ticketing. When the next big event is announced, I’ll be among the first notified so I can snag my NFT ticket and not miss out.

Each of these stories highlights how Unchained provides benefits to its stakeholders. Fans get authenticity, collectibles, and fair prices; artists get fairness, royalties, and engagement; venues get security and insights. These align closely with the project’s mission and target audience needs (fans seeking authentic access and collectibles, artists wanting fair royalties & direct engagement, venues needing fraud prevention & analytics)[9]. As development continues, we will expand on these stories, ensuring the implemented features satisfy the underlying user needs.

## APIs and Integrations
Unchained integrates with several external services and platforms to deliver its functionality. Here’s an overview of key APIs and third-party integrations and how they connect to our system:
- Blockchain Network (Polygon): All NFT tickets and smart contracts are deployed on the Polygon blockchain (an EVM-compatible network). We connect to Polygon via standard RPC endpoints (e.g., Infura or Alchemy may be used under the hood, though not explicitly mentioned). The ethers.js library and Wagmi hooks handle the low-level interaction (sending transactions, reading contract state). From the app’s perspective, when a user buys a ticket, a transaction is sent to the Polygon network which mints the NFT to their wallet. Similarly, checking ticket validity at event time involves reading the NFT’s ownership from the blockchain. This integration is fundamental – the decentralized ledger is what provides security and transparency.
- Wallet Connectivity (RainbowKit & Coinbase Wallet): The app integrates RainbowKit (a popular React library for wallet connections) along with Coinbase Wallet SDK for an optimal multi-wallet support. This means users can click “Connect Wallet” and use MetaMask, Coinbase Wallet, WalletConnect, etc. RainbowKit provides a polished UI modal for selecting and connecting wallets, while Coinbase’s SDK ensures compatibility and a seamless link to Coinbase’s user base. This integration abstracts a lot of Web3 complexity and provides a secure way for users to sign transactions (e.g., when purchasing a ticket NFT).
- Coinbase OnchainKit: This is a newer toolkit by Coinbase (especially for the Base L2 chain) that provides components and utilities for on-chain app development. While not fully implemented yet, we plan to leverage OnchainKit for features like gasless transactions or simplified contract integration if deploying on Coinbase’s Base network. For example, OnchainKit’s account abstraction might allow Unchained to sponsor gas fees for first-time users (making it easier for non-crypto-savvy fans to use the platform). It can also offer standardized components for transaction flows. This integration is exploratory but could enhance user experience by reducing blockchain friction.
- SerpAPI (Google Events API): During development (and possibly in production for event data aggregation), Unchained uses SerpAPI to fetch event listings from Google’s Events results. SerpAPI is a scraping API that can query Google for events in a given location or query. We integrate this to populate our app with sample events and details (title, date, venue, event link, etc.) without having our own events database initially. The API is used server-side or client-side with an API key. For example, on the homepage, the app might call our backend (or directly SerpAPI) to get “Concerts in New York this week” and display them. We have a SerpAPI key set up (see configuration) that allows a certain number of calls per month. In development, we often mock or cache this data to avoid hitting rate limits.
- NFT.Storage / IPFS: For storing metadata like event descriptions, images, or even the minted ticket stub images, we use NFT.Storage which is built on IPFS. When an organizer creates a new event ticket NFT, an JSON metadata file (containing fields like name, description, image URL, event date) is uploaded to IPFS via NFT.Storage, returning a content hash (CID). That CID is then referenced in the NFT’s metadata URI. The integration with NFT.Storage is through its API – we send an HTTP request with the file or JSON, and get back an IPFS link. This ensures media content for tickets is distributed and not reliant on a single server. Users retrieving their ticket info load it from IPFS, which is decentralized.
- Analytics and Tracking: (Planned integration) We may use services like Google Analytics or a Web3 analytics tool to understand user behavior on the DApp. However, given the privacy-conscious ethos of blockchain communities, we will be cautious with tracking. If used, it might be an anonymized page view tracker or something like Vercel Analytics for performance monitoring[29]. This helps us see how the app performs and which features are most used, guiding further development.
- Email/Notification Service: (Future integration) To manage the waitlist and user communications, an integration with an email service (like SendGrid or Mailchimp) might be utilized. For example, when a user joins the waitlist (inputs their email on “JoinTheResistance” page), we store that and possibly send a confirmation or periodic newsletter. This would involve either a small backend function hitting an email API or a third-party automation. Not implemented yet but foreseen.
- Payment Gateway (Fiat to Crypto): One challenge is enabling users who don’t hold cryptocurrency to buy NFT tickets. We are considering integrating a service like Coinbase Pay or MoonPay – something that can handle fiat-to-crypto seamlessly. This would allow a user with just a credit card to purchase an NFT ticket, with the service handling the backend conversion and minting. This integration would be important to onboard mainstream users, though it comes with KYC and regulatory overhead. At the moment, users are expected to have a crypto wallet and MATIC/ETH for gas, but this is an area for improvement.

Each of these integrations plays a role in the overall system. For instance, SerpAPI provides the event content that makes the app immediately useful; Polygon blockchain provides the trust and enforcement for tickets; wallet integrations provide usability for Web3; and NFT.Storage ensures decentralized persistence of data. We’ve designed the system such that if any integration is unavailable (say SerpAPI rate limit exceeded), the app fails gracefully (e.g., show cached events or a message). Environment variables and config files store API keys and IDs securely (e.g., the SerpAPI key is stored in .env and set in Vercel config, not hardcoded).

By using established services and APIs, we avoid re-inventing the wheel and can focus on our unique logic. All external integrations are documented so that developers (and AI assistants) understand how to call them. For example, developers can consult SerpAPI’s docs to format queries (the integration is straightforward: a REST GET request with our key and query parameters). The Tech Stack table in our README also summarizes many of these connections (e.g., wagmi for Web3, Vercel for hosting, etc.).

## Documentation & Completion Tracking
As part of our development workflow, we maintain comprehensive documentation of completed features and milestones. This serves as both a historical record and a reference for team members (human and AI):
- Phase Completion Files: For each major phase of the project migration or development, maintain a running `PHASE[N]_COMPLETE.md` file in the project root. This file should be updated incrementally as features are completed, NOT created only at the end of a phase.
- Completion Summary Format: When completing a significant feature or set of features, add a detailed summary to the appropriate phase completion file. Each summary should include:
  - **Problem Statement:** What issue was being addressed
  - **Solution Overview:** High-level approach taken
  - **Files Modified/Created:** List all files with links and line numbers where applicable
  - **Implementation Details:** Technical specifics including code snippets, configuration changes, API integrations
  - **Results/Impact:** Measurable outcomes, performance improvements, UX enhancements
  - **Dependencies Added:** Any new packages with version numbers
  - **Testing/Build Status:** Confirmation that changes build successfully
- Update Frequency: Add summaries to the completion file immediately after finishing a feature or milestone. Do not batch updates - this ensures the documentation stays current and serves as a real-time progress tracker.
- Format Example: See PHASE3_COMPLETE.md for the standard format. Each feature should have:
  - Clear heading (## Feature Name)
  - Problem/Solution structure
  - Code examples with syntax highlighting
  - File references with clickable links (e.g., [filename](path/to/file.ts:123))
  - Visual indicators (✅ for completed, 🚧 for in-progress)
- Benefits: This practice ensures:
  - Historical record of what was completed and when
  - Easy onboarding for new team members or AI assistants
  - Clear demonstration of progress to stakeholders
  - Reference material for similar future implementations
  - Context preservation across long development sessions

## Development Workflow & Automation
To maximize efficiency and consistency, we have a defined development workflow. This includes how to run and build the app, as well as techniques to automate repetitive tasks using scripts, aliases, and our AI helpers. Below are guidelines and tips for the development process:
- Running the App Locally: After cloning the repository and installing dependencies (npm install), you can start the development server with npm run dev. This launches the Vite dev server, usually at http://localhost:5173, with hot-reloading. During development, you’ll also need access to certain services:
  - Make sure you have a local Ethereum node or testnet configuration if interacting with contracts (e.g., have a MetaMask wallet configured to Polygon Mumbai for testing, or run npx hardhat node if doing local Hardhat testing).
  - If using SerpAPI live, ensure you have the API key in your .env (e.g., VITE_SERPAPI_KEY) and the dev server will proxy or include it appropriately. Alternatively, you might run a mock of the events API – e.g., serve a events.json from public for development to avoid using the API constantly.
  - The dev server will compile and serve the React app, and any changes in src/ will hot-reload. Check the terminal for any compilation or lint errors and fix them as they arise. We treat warnings seriously as well – addressing those keeps the app clean.
- Building for Production: To generate an optimized build, run npm run build. This uses Vite to bundle the React app (minify JS/CSS, etc.) into a dist/ directory. You can then run npm run preview to test the production build locally. This step is also what Vercel does during deployment. Always test critical flows (like connecting a wallet, buying a test ticket) on the preview build to ensure no environment-specific issues. The build output will be used by Vercel to serve the app.
- Automation with NPM Scripts: We have defined several convenient NPM scripts in package.json:
  - npm run dev – as mentioned, starts the dev server.
  - npm run build – builds the app for production.
  - npm run lint – runs ESLint across the codebase to check for coding standard violations.
  - npm run format – runs Prettier to auto-format all files.
  - npm run test – (if tests are added) executes the test suite.
  - npm run deploy – (if configured) could be a shortcut to deploy the app (e.g., via Vercel CLI) from local.

Using these scripts simplifies common tasks so you don’t have to remember long commands. For example, instead of manually running a series of commands to deploy, a single npm run deploy could encompass build + test + vercel deploy steps. Always check package.json for the latest list of scripts available.

- Command Aliases for Productivity: To speed up repetitive command-line tasks, consider setting up shell aliases. For instance, if you find yourself frequently typing npm run dev, you can add an alias like alias dev="npm run dev" in your shell profile. Then simply typing dev will start the app. Similarly, you might alias npm run lint:fix as lintfix or nf. These aliases reduce keystrokes for common tasks and ensure you run the correct scripts each time (minimizing human error in typing long commands). They are especially useful for tasks you run dozens of times a day (starting/stopping the server, running tests, etc.). Developers on different OS/shells can adapt alias syntax as needed (e.g., using a Windows batch script or a Linux alias in .bashrc). The main idea is to automate anything you do frequently – for example, if deploying via CLI, alias the deploy command with all necessary flags. This optimization of workflow allows you to focus more on coding and less on typing commands.
- Utilizing AI Assistants in Development: Since we have powerful CLI-based AI coding assistants (Claude Code and OpenAI Codex), make them a part of your workflow:
  - Pair Programming with AI: Treat the AI assistant like a teammate. For example, if you’re not sure how to implement a certain functionality, you can prompt Claude in natural language: “Help me write a React component that does X,” or “Refactor this function for better readability.” The key is to be specific and iterative. Provide the AI with sufficient context (you can paste in relevant code or refer to file names) and clearly state the requirements. Clear, detailed prompts lead to better outputs[30]. If the AI’s first answer isn’t perfect, refine your prompt or ask follow-up questions. Don’t hesitate to have a dialogue: e.g., “Explain why you chose this approach,” or “That wasn’t quite right, the component needs to do Y, not X.” Engaging in this back-and-forth yields the best results[31].
  - Maintaining Quality Control: Even though the AI can generate code, you (the developer) are responsible for integrating and verifying it. Always review AI-generated code for correctness, security, and style. Ask the assistant to clarify any part of the code you don’t understand – for instance, “Can you comment this code and explain what each section does?” This can surface errors or assumptions. By treating the AI’s output as if it were a junior developer’s work, you ensure it meets the project’s standards. In fact, you can use the AI to double-check itself: after getting a snippet, prompt it with “Are there any potential bugs or edge cases in the above code?” This often reveals issues or improvements.
  - Automating Repetitive Coding Tasks: Leverage the assistants to avoid boilerplate writing. If you need to create 5 similar components for different entities, you might do one manually and then ask Codex or Claude to generate the rest following the same pattern. The AI can quickly produce template code which you can fine-tune. Additionally, Claude Code (with Sonnet 4.5) is capable of performing multiple actions in one go. It can, for example, create a new file, update an existing file, and run a command concurrently as part of one task execution[32]. This means you could instruct, “Generate a new hook for fetching data and update the App component to use it, then run the tests,” and Claude might attempt to do all of that in sequence. While one should use such powerful autonomy carefully, it can speed up complex refactors or project-wide updates.
  - Prompt Management: Keep a memory of successful prompts and even consider creating an AI Cheat Sheet file. For instance, document prompts that worked well (“Ask Claude to optimize a function by doing X”). This can be shared with the team so everyone benefits from effective techniques. Also, maintain awareness of the context window – feed the AI this instructions.md and relevant code when asking for help so it has full project understanding. Claude Code is designed to read and comprehend the entire repository context[33], and Codex CLI can be pointed at the project directory, so both can utilize the architecture and style info when generating code.
  - Treat it as a Team Member: Ultimately, adopt a pair-programming mindset with AI – it works best when you collaborate rather than delegate blindly. Engage in a conversation: generate code, test it, discuss the outcomes with the AI, and iterate. This approach not only yields better code but also helps you learn and maintain a high-level understanding of the project (the AI might surface considerations you hadn’t thought of). The most productive sessions come from this interactive workflow of prompt -> review -> refine -> repeat, much like working with a human partner[31]. Remember that the AI can suggest design patterns or libraries too – feel free to ask its opinion (“Is there a better way to implement this feature?”) and then verify whatever it suggests.
  - Continuous Integration (CI): (If set up) Commits to certain branches might trigger automated builds/tests (for example, via GitHub Actions or Vercel’s CI). Ensure that your changes pass all tests and lint checks before pushing. It’s good practice to run npm run lint && npm run test locally pre-push, or use a pre-push git hook, so that the CI will likely pass. This keeps our main branch stable.

By following this workflow and utilizing automation, we reduce manual effort and catch issues early. Simple steps like using aliases for shell commands, or asking the AI assistant to handle routine code, can save significant time. The combination of human insight with AI speed can be extremely powerful: for instance, an AI assistant can generate 10 variations of a function in seconds – but you choose the best one that fits. Always maintain that balance of speed and thoughtfulness.

Finally, keep documentation (like this guide) updated as the workflow evolves. If you add a useful alias or script, or discover a new best practice with the AI pair programmer, record it here so the whole team (and any new AI that reads the repo) can benefit. Development is an ongoing learning process, and we aim to continuously optimize it.

## Deployment
Deploying the Unchained app (frontend and backend functions) is streamlined through Vercel. Below are the deployment instructions and considerations for launching the app to a live environment:

### Vercel Deployment Process
We use Vercel for hosting, which offers two main ways to deploy:
1. Deploy via Git (CI/CD): Our repository is linked to Vercel, so any push to the main branch (or a designated production branch) will trigger an automatic deployment[34]. Vercel’s Git integration will detect the React project (Vite) and use the correct build settings by default[35]. To set this up initially, one must:
2. Log in to Vercel and use the Import Project flow to connect the GitHub/GitLab/Bitbucket repository[34]. Choose the repo and branch, and Vercel will configure a project.
3. Define any needed environment variables in the Vercel dashboard (under Project Settings -> Environment Variables). For Unchained, this includes things like SERPAPI_API_KEY and any other API keys or secrets (these will be injected at build/runtime).
4. After linking, every code push results in Vercel building the app (npm install, then npm run build) and deploying it. Vercel provides preview URLs for each pull request and a production URL for the main branch[36].
5. Once deployed, the app will be accessible at <project-name>.vercel.app by default, unless a custom domain is configured[37]. For example, if our project is named "unchained", it might live at unchained.vercel.app initially.
6. Deploy via Vercel CLI: For manual deployments or local testing of deployment, developers can use the Vercel CLI tool. Steps:
7. Install Vercel CLI globally: npm i -g vercel. Authenticate it (vercel login).
8. Run vercel in the project directory. The first time, it will prompt for some configuration (project name, which team/account, etc.). It generally auto-detects that this is a React/Vite app and applies appropriate defaults[35].
9. The CLI will upload the project, run the build on Vercel’s servers, and give you a deployment URL (often a unique preview URL unless deploying to production explicitly). Use vercel --prod to force a production deployment on the main domain.
10. This method is useful if you want to deploy a feature branch temporarily or if you need to ensure something works in Vercel’s environment exactly as it does locally.

### Environment & Configuration
Before deploying, ensure that all required environment variables are set in Vercel. For Unchained, critical ones include:
- SERPAPI_API_KEY – used by the backend or frontend to fetch event data. (If the fetching is done client-side, we might prefix it with VITE_ to embed during build. If serverless, just use it in the function.)
- Any API keys for blockchain RPC providers (e.g., an Infura project ID if we use one), or Thirdweb keys if applicable.
- If using a testnet (like Polygon Mumbai) for demo, environment variable might indicate which network or contract addresses to use (e.g., REACT_APP_NETWORK = mumbai). These should be set such that the build picks up the correct config.

In local .env files, we mimic these values for testing. Remember not to commit real secrets; Vercel’s dashboard should hold the production secrets.

### Post-Deployment Testing
After deploying, it’s important to test the live site:
- Open the Vercel deployment URL in a browser and click through the app. Verify that pages load without errors, and that blockchain interactions work (you might need a wallet connected to Polygon testnet for testing).
- Check the console for any runtime errors. Sometimes environment-specific issues (like case-sensitive file paths on Vercel’s Linux environment, or missing env vars) can appear – fix those and redeploy if needed.
- Test the serverless functions (if any). For instance, if we had an API route for events, try hitting https://yourapp.vercel.app/api/events to see if it returns expected data. Ensure CORS is okay if front-end calls back-end on the same domain (Vercel handles this generally by serving them from one domain).

### Custom Domain
If a custom domain is desired (e.g., unchained.com), go to Vercel settings and add the domain. Vercel will guide DNS configuration (adding CNAME records). Once set, the app will be accessible at the custom domain, and Vercel will provision SSL automatically. This doesn’t change how we deploy, it just changes where the live site resides.

### Deployment of Smart Contracts
This is somewhat separate from Vercel (which covers the web app). For the blockchain aspect:
- If deploying new versions of the NFT ticket smart contract, you’d use Hardhat or Thirdweb CLI. This might involve running npx hardhat deploy --network polygon or using the Thirdweb dashboard to deploy a contract. Keep track of contract addresses and update the frontend config if they change.
- We might maintain a file like src/constants/contracts.js that holds the addresses/ABIs of deployed contracts. When deploying to mainnet or testnet, update those accordingly and redeploy the frontend so it knows where to interact.

### Monitoring and Logs
Vercel provides a “Functions” tab where you can see logs from serverless function executions. If our app has any backend code (e.g., an API route that fetches from SerpAPI or interacts with blockchain via Node), we can check those logs for errors (in Vercel’s dashboard or via vercel logs). Additionally, if using external logging or tracking (Sentry, LogRocket), ensure they are capturing events in production.

### Scaling Considerations
Vercel will automatically scale the static front-end globally on its Edge network. The serverless functions scale per request (cold starts might happen if low traffic). Given our app is read-heavy (users browsing events) and write-light (minting tickets occasionally), Vercel should handle this well. If we anticipate very high traffic for a big on-sale event, we might need to consider performance (e.g., caching event data or using a queue for mint transactions). At our current stage, Vercel’s default setup is sufficient.

### Summary of Deployment Steps
For clarity, a concise step-by-step for a fresh deployment is:
1. Preparation: Commit all changes and ensure npm run build passes locally. Set environment variables on Vercel dashboard (one-time setup).
2. Trigger Deploy: Either push to the main branch if CI is configured, or run vercel --prod using the CLI.
3. Vercel Build: Vercel will detect the project and run the build (React app) and package serverless functions. No manual config needed in most cases[38].
4. Verification: Once deployed, access the live URL. Test the application’s main functionalities (connect wallet, view events, etc.) on the live site.
5. Post-deploy Actions: If everything looks good, announce or continue development. If issues are found, fix in code and repeat the deployment (Vercel makes rollbacks easy too if needed).

By following these instructions, deploying updates to Unchained should be a smooth, repeatable process. Vercel’s integration means we usually just focus on writing code and merging pull requests – the rest is automated. In case of any deployment-specific issues, consult Vercel’s documentation or their community forums, as they have extensive guides on common pitfalls for React/Vite apps. Overall, with proper setup, deploying Unchained is as simple as “git push” and letting Vercel handle the rest[36].

## References
- [1] [3] [27] unchained_style_guide.md  
  file://file-3KaHHkWYntS5GrivaL8LwG
- [2] [4] [5] [6] [7] [8] [9] [10] [11] [12] [17] [18] [19] [20] [21] [22] [23] [24] [28] README.md  
  file://file-XAALWw3VtmH4pQgrDEMRCe
- [13] [14] [33] Claude Code - AI Pair Programming Assistant | ClaudeCode.io  
  https://claudecode.io/
- [15] GitHub - openai/codex: Lightweight coding agent that runs in your terminal  
  https://github.com/openai/codex
- [16] slugify.js  
  file://file-UBX9GHo4NkWonUphuP1vys
- [25] What is Prettier? · Prettier  
  https://prettier.io/docs/
- [26] useFuseSearch.js  
  file://file-XzAVGDssbUMgNm15mQXNH4
- [29] [34] [35] [36] [37] [38] How to Deploy a React Site with Vercel  
  https://vercel.com/guides/deploying-react-with-vercel
- [30] [31] Best Practices I Learned for AI Assisted Coding | by Claire Longo | Medium  
  https://statistician-in-stilettos.medium.com/best-practices-i-learned-for-ai-assisted-coding-70ff7359d403
- [32] Introducing Claude Sonnet 4.5 \ Anthropic  
  https://www.anthropic.com/news/claude-sonnet-4-5


---

## Appendix: Original Unformatted Content

```text
Unchained – Project Overview & Developer Guide
Overview
Project Goals & Problem Statement:
Unchained is a decentralized ticketing platform built to disrupt the monopoly of traditional event ticketing (e.g. combating Ticketmaster-like control). It leverages blockchain technology to eliminate counterfeit tickets, prevent scalping, reward loyal fans, and empower the community of artists and attendees[1]. In today’s ticketing industry, users face rampant fraud and price gouging by resellers; artists and venues lose control over secondary sales. Unchained addresses these issues by ensuring fairness, transparency, and fan rewards through smart contracts[2]. Its mission-driven approach aims to create a transparent, fan-first ecosystem free from monopolistic control[3].
Core Functionality:
Unchained issues event tickets as NFTs (non-fungible tokens) on the blockchain, enforcing authenticity and programmable resale rules. Key features of the platform include:
• NFT Ticketing with Royalties: Event tickets are minted as ERC-721 NFTs, optionally with ERC-2981 royalty standards so that organizers or artists get a cut from any resale[4]. Smart contracts automatically prevent scalping by capping resale prices or enforcing royalties on secondary transfers[4]. This ensures tickets cannot be easily flipped for profit without benefiting the content creators.
• Authenticity & Anti-Fraud: Because each ticket is a unique token on the blockchain, it’s impossible to counterfeit. Venues can easily verify on-chain that a ticket is genuine, eliminating fake tickets and fraud at entry[1].
• Collectible Ticket Stubs: After an event, the NFT ticket serves as a digital collectible (souvenir) for the fan[5]. Fans can keep or trade these NFT ticket stubs, which might unlock future perks. This builds a sense of community and rewards fandom beyond the event itself.
• Analytics & Dashboards: The platform provides dashboards for venues and artists[6]. Organizers can see real-time data on ticket ownership, transfers, and attendance. This actionable analytics information (e.g. how many tickets were resold, fan demographics, etc.) helps them make informed decisions for future events.
• Fan Loyalty & Rewards: A built-in loyalty system rewards fans for attending events and holding tickets[6]. For example, fans might earn tokens or exclusive access to merchandise and presales after attending multiple events. This encourages genuine fans to participate and remain engaged.
• Event Discovery & Community: Users can search for events, venues, or artists via a discovery interface with fuzzy search[7]. A landing page (“Join The Resistance”) acts as a waitlist/signup funnel for early adopters[8], reflecting the project’s punk/activist branding. This helps build a community and user base before full launch.
Overall, Unchained’s target audience includes music fans (who want authentic tickets and collectible experiences), artists (who seek fair royalties and direct fan engagement), and venues (needing fraud prevention and better analytics)[9]. By aligning the interests of these groups, the platform strives to create a fairer, more transparent ticketing ecosystem powered by blockchain.
Tech Stack
This project uses a modern web and blockchain stack. Below is an overview of all major technologies, libraries, and frameworks used (with versions where applicable):
• Frontend: React (v18+) single-page application, bootstrapped with Vite for fast builds and dev server[10]. The UI is styled using Tailwind CSS (v3) along with custom CSS modules for unique design elements. Routing is handled by React Router (v6+).
• Backend: Node.js (v18 LTS) powers any server-side logic. The app uses a lightweight Express (v4) server for API endpoints, which in production is deployed as serverless functions on Vercel. This means each API route runs as a standalone cloud function, enabling scalable on-demand backend execution.
• Blockchain & Smart Contracts: The platform is built on the Ethereum Virtual Machine (EVM) ecosystem, specifically targeting the Polygon network (a cost-effective Ethereum L2) for deploying smart contracts[10]. Smart contracts are written in Solidity and managed using Hardhat (2.x) during development[11]. We also leverage Thirdweb SDK/tools for quick contract deployment and management as needed[12]. The NFT ticket contract implements standards like ERC-721 for tokens and ERC-2981 for royalties.
• Web3 Integration: On the client side, we use the ethers.js library and Wagmi React hooks (v0.x or v1) for blockchain interactions. RainbowKit and the Coinbase Wallet SDK are integrated to provide a smooth wallet connection UI. This allows users to connect with MetaMask, Coinbase Wallet, or others to purchase and hold their NFT tickets. The Coinbase Onchain Kit is explored as well – it offers pre-built components and utilities for building on-chain user experiences (particularly useful if integrating with Coinbase’s Base network or account abstraction features).
• Storage: Event and ticket metadata (images, descriptions) are stored off-chain using decentralized storage. We utilize NFT.Storage (an IPFS pinning service) to store media and JSON metadata on IPFS (InterPlanetary File System). This ensures that ticket details and artwork remain publicly accessible and tamper-proof.
• Search: For client-side searching and fuzzy matching through events, artists, or venues, we include Fuse.js. This lightweight library enables substring and approximate text matching to improve the user’s ability to find events (e.g., searching by partial artist name or venue).
• Hosting & Deployment: The application is hosted on Vercel, which provides an all-in-one platform for static frontends and API functions. Vercel is connected to our Git repository for continuous deployment; every push to main triggers a rebuild and redeploy. (See Deployment section for details.)
• Developer Tooling (AI Assistants): To boost productivity, the team leverages AI coding assistants in the development workflow. Notably, we use Anthropic’s Claude Code (powered by the Claude Sonnet 4.5 model) and OpenAI’s Codex CLI:
• Claude Code (Sonnet 4.5): An advanced AI pair-programming assistant by Anthropic. Claude Code can understand the entire project repository context and provide intelligent code suggestions, refactorings, and even generate new files based on natural language instructions[13]. Sonnet 4.5 is the underlying model that grants Claude Code extended autonomous coding capabilities, allowing it to handle long coding sessions and complex tasks with improved reasoning[14]. In practice, we use Claude in the CLI/IDE to help write boilerplate, find bugs, and accelerate development.
• OpenAI Codex CLI: An AI coding agent from OpenAI that runs locally in the terminal[15]. Codex CLI can interpret commands or prompts and directly modify code or execute tasks. It’s essentially an AI that can take shell instructions and code context to assist with implementations. We use Codex for on-demand code generation and to automate repetitive coding tasks through the command line.
By combining this tech stack, Unchained delivers a full-stack DApp (Decentralized Application) experience: a React/Tailwind UI, a Node/Vercel serverless backend, and smart contracts on Polygon, all integrated seamlessly. The inclusion of AI coding tools (Claude and Codex) is also an innovative part of our development process, enabling faster and smarter coding.
Project Structure
The repository follows a structured layout to organize source code and assets. Below is an outline of the core project folders and files, with explanations for each:
• src/assets/ – Contains static assets like images, icons, and texture files used in the app. For example, background images or logo files referenced in components would reside here.
• src/components/ – Reusable UI components for the React frontend. These are usually small, self-contained pieces of the interface (buttons, cards, navigation items, etc.) that can be composed to build pages. For instance, EventCard.jsx displays a summary of an event (with image, title, date) and is used across different pages.
• src/pages/ – Page-level components representing different screens or routes in the application. Each page might import many components. Examples include Home.jsx, EventDetail.jsx, or TicketView.jsx. Pages correspond to routes in the React Router configuration.
• src/utils/ – Utility modules and helper functions. These contain non-React logic that can be reused across the app. For example, a slugify.js for creating URL-friendly strings from event names[16], an openGoogleMaps.js to abstract opening external map links, or other data processing helpers. Placing these in utils keeps components cleaner and promotes reuse.
• src/styles/ – All styling files (CSS) are organized here. We use a combination of Tailwind CSS utility classes and custom CSS. The styles folder is further subdivided for maintainability:
• styles/base/ – Global base styles such as resets (e.g. _reset.css), typography defaults (\_typography.css), and general global rules (\_globals.css for things like box-sizing, element defaults)[17]. These are loaded first to establish a baseline.
• styles/tokens/ – Design tokens and variables, e.g. \_colors.css defining the central color palette, \_spacing.css for spacing scale (margin/padding sizes), \_typescale.css for font sizes and line-heights[18]. By defining these in one place, we ensure consistency (the values here correspond to the brand style guide).
• styles/components/ – Component-specific CSS classes. For example, button.css contains styles for the custom button styles used in the app, input.css for form elements, card.css for card components like event cards[19]. These are imported by the corresponding JSX components or by the main CSS.
• styles/layout/ – Layout helpers, such as grid.css (common grid or flexbox utilities) and containers.css (max-widths for containers, layout structure)[20].
• styles/index.css – The main stylesheet that imports all the other CSS files in the correct order[21]. This is the file ultimately loaded by the app to apply all styles.
• src/App.jsx – The root React component that defines the overall application structure and routing. This typically includes the Router setup (mapping URL paths to the components in pages/), as well as any global context providers (for theme, authentication, API data, etc.). It can be thought of as the “controller” of the frontend. [22]
• src/main.jsx – The entry point for the React application. This is where we mount the App component onto the DOM. Vite uses this as the bootstrap file. It usually contains something like ReactDOM.createRoot(...).render(<App />). (If we were using TypeScript or advanced configurations, this is also where HMR and strict mode might be set up.)[22]
• (Potential) src/api/ – In a full-stack project on Vercel, we might have an api/ directory for serverless function files (e.g., src/api/checkout.js for a ticket purchase endpoint). In this project, API calls for event data might instead be handled client-side (for example, fetching from SerpAPI directly in the frontend), so an api/ folder may not be present. If future backend functions are needed (like a custom endpoint), this is where they would live, and Vercel would deploy them automatically.
• Other config files – The project root includes typical configuration files: package.json (npm dependencies and scripts), possibly .eslintrc.json or .prettierrc (for linting/format rules), and smart contract directories if any (e.g., a contracts/ folder or Hardhat config if Solidity code is present). There’s also a README.md which provides high-level info (much of which is reflected in this guide).
This structure groups related files together, making the project maintainable and scalable. For instance, all UI components are in one place, styles are centralized, and utilities are separated from React components. The layout shown above is drawn from the project’s architecture documentation[23][24], ensuring that anyone reading this guide or using an AI assistant on the repo has a clear map of where things are.
Coding Standards
We adhere to consistent coding conventions and best practices to maintain code quality and readability. Below are the style guidelines, linting rules, and design patterns followed in the Unchained project:
• Code Style & Formatting: We use Prettier as an automated code formatter across the project. All code should be formatted with Prettier’s default conventions (2-space indentation, semicolons, quotes, etc.) on save or before commit. Prettier ensures that the entire codebase has a consistent style, automatically reprinting code in a unified format[25]. This eliminates debates over styling – developers can focus on logic, and the formatter takes care of spacing, line breaks, and so on. (Prettier is widely considered an industry-standard tool for JS formatting, and using it helps us follow common best practices out-of-the-box.) We also encourage using an editor integration for Prettier or a pre-commit hook, so that code is always formatted correctly.
• Linting & Best Practices: In addition to formatting, we enforce code quality via ESLint. The project is configured (or plans to be configured) with an ESLint setup – likely extending a well-known style guide such as Airbnb or using eslint:recommended with Prettier integration. The linter will catch common bugs or anti-patterns (unused variables, undefined variables, improper React hook usage, etc.). All team members (and AI assistants) should ensure code passes lint checks. For example, follow naming conventions: use camelCase for variables/functions, PascalCase for React components, and UPPER_SNAKE_CASE for constants. Prefer const and let over var, and use ES6+ syntax (arrow functions, spread operators, template strings) for cleaner, modern JavaScript.
• Project Patterns: We follow a component-driven architecture in React. That means keeping components focused and reusable. Functional components (with hooks) are used exclusively (no legacy class components). Related to that, React hooks are used for stateful logic and side effects – e.g., a custom hook useFuseSearch encapsulates search logic[26], and Context API is used for global state like events data (see APIContext usage in components). This pattern keeps view components (pages and UI elements) declarative and offloads data fetching or logic to hooks and context providers.
• UI/UX Consistency: All UI elements and styling follow the design system outlined in our Style Guide. Developers should use the predefined CSS classes (from styles/) and Tailwind utilities instead of arbitrary new styles, to maintain consistency. For example, use the color variables and spacing scales defined in styles/tokens/\_colors.css and \_spacing.css rather than hardcoding hex colors or pixel values. The “punk/underground” aesthetic (gritty textures, neon accents) described in the style guide should be reflected in the components – e.g., using the Resistance Red and Toxic Neon colors for call-to-action elements as specified. When in doubt, refer to Unchained Style Guide for visual guidelines on components like buttons, cards, etc. This ensures the app’s look stays unified.
• Accessibility: We prioritize building an accessible application. Follow ARIA and accessibility best practices: use semantic HTML elements where possible (e.g., <button> for clickable actions, <nav> for navigation regions), and add ARIA labels/roles for custom components. All interactive elements must be reachable via keyboard (tab navigation) and provide visual focus states. We also ensure sufficient color contrast in text and UI (meeting WCAG AA standards)[27]. For example, the design palette was chosen with contrast in mind and developers should not deviate in ways that reduce readability. Any image must have an alt attribute describing it (especially important if the image conveys info). By adhering to these, we make the app usable for as many people as possible.
• Git & Commit Conventions: (If applicable) We follow a conventional commit style or at least clear commit messages. When using the AI assistants for generating code, it’s still the developer’s job to summarize changes in commit messages for clarity. Feature branches and pull requests should be used for major features, with code reviews (even if AI-generated code) to maintain quality.
• Testing & QA: (Planned) Testing is crucial especially with AI-generated code. We intend to write unit tests (perhaps using Jest or Vitest) for critical functions like smart contract interactions or utility functions. Test files would mirror the structure (e.g., utils/slugify.test.js). Ensure new code is covered by tests where feasible. Even if not fully in place yet, developers should manually test features (e.g., actually attempt an NFT purchase in a test environment, or run through the ticket redemption flow) to validate that everything works as expected.
In summary, code contributors (human or AI) should produce clean, readable code that aligns with the established style. Prettier handles the micro-formatting, while developers must enforce logical consistency and project conventions. By following these standards, we ensure the codebase remains maintainable and coherent as the project grows.
User Stories
To understand the platform’s features from an end-user perspective, here are key user stories categorized by user type (fan, artist/organizer, venue). These stories illustrate what each type of user can achieve with Unchained, and they reflect the platform’s core value propositions:
• As a Music Fan (Ticket Buyer): I want to discover upcoming events easily and buy authentic tickets with confidence. Using Unchained, I can search for events or artists and purchase a ticket as an NFT directly from the official source. This guarantees that my ticket is not counterfeit and I won’t be scammed at the door. After the event, I still hold the NFT as a digital collectible stub, which might grant me exclusive content or just serve as a memorable keepsake. I also enjoy loyalty rewards for using the platform – for example, being a repeat attendee could unlock special perks or early access to future tickets. (Target outcome: fans get legitimate tickets and added value like collectibles and rewards, addressing their desire for authentic access and a closer connection to the experience[28].)
• As an Avid Fan (Resale Participant): I want the ability to resell my ticket if I can’t attend, but in a fair way. On Unchained, if I list my NFT ticket for resale, the platform’s smart contract might enforce a price cap or automatically include a royalty. This means I can recoup my cost (or a modest profit) but cannot scalp the ticket at exorbitant prices, keeping things fair for other fans. I’m okay with this because it also means if I’m buying a resold ticket, I won’t have to pay an outrageous markup – the system protects me either way. Plus, any resale royalty might go to the artist or event organizer, supporting them rather than just profiteers.
• As an Event Organizer/Artist: I want control over my event’s ticketing and to ensure true fans get access. With Unchained, I can mint a fixed number of NFT tickets for my event and sell them directly to fans without middleman platforms taking a huge cut. I can set rules like “tickets cannot be resold above face value” or “I receive 10% of any resale via royalty.” This guarantees that scalpers cannot exploit my tickets, and if they do resell, I share in the upside[28]. I also get a dashboard that shows who my top fans are (e.g., someone who holds many of my event NFTs) and I can reward them with special NFTs or experiences. After the show, I know each ticket NFT’s holder – this opens up new marketing opportunities like airdropping a thank-you token or offering discount codes to those who attended. Essentially, I gain actionable insights and a direct relationship with my audience that wasn’t possible with traditional ticketing.
• As a Venue Manager: I need to ensure smooth entry and eliminate fraud at the gate. Using Unchained’s system, my team can scan a ticket’s QR code or wallet at entry and instantly verify on the blockchain that it’s a valid ticket that hasn’t been used before. This gives us confidence that no fake tickets will slip through[1], avoiding any confrontation with fans holding bogus tickets. The entry process becomes quicker and more secure. Additionally, I can see analytics on attendance: because each NFT ticket is traceable, I can know how many people transferred their tickets, how many checked in, etc. Over time, this helps with planning (for instance, identifying that a certain percentage of tickets always get resold might inform pricing or security measures). The data and fraud prevention together provide a better experience for both staff and attendees[9].
• As a New User (Waitlist Member): I am interested in the concept and want to join the platform early. I can sign up on the “Join The Resistance” waitlist page. As a member of the waitlist or early adopter, I might receive updates, beta access, or even an NFT badge that labels me as part of the founding community. This makes me feel involved in the movement to change ticketing. When the next big event is announced, I’ll be among the first notified so I can snag my NFT ticket and not miss out.
Each of these stories highlights how Unchained provides benefits to its stakeholders. Fans get authenticity, collectibles, and fair prices; artists get fairness, royalties, and engagement; venues get security and insights. These align closely with the project’s mission and target audience needs (fans seeking authentic access and collectibles, artists wanting fair royalties & direct engagement, venues needing fraud prevention & analytics)[9]. As development continues, we will expand on these stories, ensuring the implemented features satisfy the underlying user needs.
APIs and Integrations
Unchained integrates with several external services and platforms to deliver its functionality. Here’s an overview of key APIs and third-party integrations and how they connect to our system:
• Blockchain Network (Polygon): All NFT tickets and smart contracts are deployed on the Polygon blockchain (an EVM-compatible network). We connect to Polygon via standard RPC endpoints (e.g., Infura or Alchemy may be used under the hood, though not explicitly mentioned). The ethers.js library and Wagmi hooks handle the low-level interaction (sending transactions, reading contract state). From the app’s perspective, when a user buys a ticket, a transaction is sent to the Polygon network which mints the NFT to their wallet. Similarly, checking ticket validity at event time involves reading the NFT’s ownership from the blockchain. This integration is fundamental – the decentralized ledger is what provides security and transparency.
• Wallet Connectivity (RainbowKit & Coinbase Wallet): The app integrates RainbowKit (a popular React library for wallet connections) along with Coinbase Wallet SDK for an optimal multi-wallet support. This means users can click “Connect Wallet” and use MetaMask, Coinbase Wallet, WalletConnect, etc. RainbowKit provides a polished UI modal for selecting and connecting wallets, while Coinbase’s SDK ensures compatibility and a seamless link to Coinbase’s user base. This integration abstracts a lot of Web3 complexity and provides a secure way for users to sign transactions (e.g., when purchasing a ticket NFT).
• Coinbase OnchainKit: This is a newer toolkit by Coinbase (especially for the Base L2 chain) that provides components and utilities for on-chain app development. While not fully implemented yet, we plan to leverage OnchainKit for features like gasless transactions or simplified contract integration if deploying on Coinbase’s Base network. For example, OnchainKit’s account abstraction might allow Unchained to sponsor gas fees for first-time users (making it easier for non-crypto-savvy fans to use the platform). It can also offer standardized components for transaction flows. This integration is exploratory but could enhance user experience by reducing blockchain friction.
• SerpAPI (Google Events API): During development (and possibly in production for event data aggregation), Unchained uses SerpAPI to fetch event listings from Google’s Events results. SerpAPI is a scraping API that can query Google for events in a given location or query. We integrate this to populate our app with sample events and details (title, date, venue, event link, etc.) without having our own events database initially. The API is used server-side or client-side with an API key. For example, on the homepage, the app might call our backend (or directly SerpAPI) to get “Concerts in New York this week” and display them. We have a SerpAPI key set up (see configuration) that allows a certain number of calls per month. In development, we often mock or cache this data to avoid hitting rate limits.
• NFT.Storage / IPFS: For storing metadata like event descriptions, images, or even the minted ticket stub images, we use NFT.Storage which is built on IPFS. When an organizer creates a new event ticket NFT, an JSON metadata file (containing fields like name, description, image URL, event date) is uploaded to IPFS via NFT.Storage, returning a content hash (CID). That CID is then referenced in the NFT’s metadata URI. The integration with NFT.Storage is through its API – we send an HTTP request with the file or JSON, and get back an IPFS link. This ensures media content for tickets is distributed and not reliant on a single server. Users retrieving their ticket info load it from IPFS, which is decentralized.
• Analytics and Tracking: (Planned integration) We may use services like Google Analytics or a Web3 analytics tool to understand user behavior on the DApp. However, given the privacy-conscious ethos of blockchain communities, we will be cautious with tracking. If used, it might be an anonymized page view tracker or something like Vercel Analytics for performance monitoring[29]. This helps us see how the app performs and which features are most used, guiding further development.
• Email/Notification Service: (Future integration) To manage the waitlist and user communications, an integration with an email service (like SendGrid or Mailchimp) might be utilized. For example, when a user joins the waitlist (inputs their email on “JoinTheResistance” page), we store that and possibly send a confirmation or periodic newsletter. This would involve either a small backend function hitting an email API or a third-party automation. Not implemented yet but foreseen.
• Payment Gateway (Fiat to Crypto): One challenge is enabling users who don’t hold cryptocurrency to buy NFT tickets. We are considering integrating a service like Coinbase Pay or MoonPay – something that can handle fiat-to-crypto seamlessly. This would allow a user with just a credit card to purchase an NFT ticket, with the service handling the backend conversion and minting. This integration would be important to onboard mainstream users, though it comes with KYC and regulatory overhead. At the moment, users are expected to have a crypto wallet and MATIC/ETH for gas, but this is an area for improvement.
Each of these integrations plays a role in the overall system. For instance, SerpAPI provides the event content that makes the app immediately useful; Polygon blockchain provides the trust and enforcement for tickets; wallet integrations provide usability for Web3; and NFT.Storage ensures decentralized persistence of data. We’ve designed the system such that if any integration is unavailable (say SerpAPI rate limit exceeded), the app fails gracefully (e.g., show cached events or a message). Environment variables and config files store API keys and IDs securely (e.g., the SerpAPI key is stored in .env and set in Vercel config, not hardcoded).
By using established services and APIs, we avoid re-inventing the wheel and can focus on our unique logic. All external integrations are documented so that developers (and AI assistants) understand how to call them. For example, developers can consult SerpAPI’s docs to format queries (the integration is straightforward: a REST GET request with our key and query parameters). The Tech Stack table in our README also summarizes many of these connections (e.g., wagmi for Web3, Vercel for hosting, etc.).
Documentation & Completion Tracking
As part of our development workflow, we maintain comprehensive documentation of completed features and milestones. This serves as both a historical record and a reference for team members (human and AI):

• Phase Completion Files: For each major phase of the project migration or development, maintain a running `PHASE[N]_COMPLETE.md` file in the project root. This file should be updated incrementally as features are completed, NOT created only at the end of a phase.

• Completion Summary Format: When completing a significant feature or set of features, add a detailed summary to the appropriate phase completion file. Each summary should include:
  - **Problem Statement:** What issue was being addressed
  - **Solution Overview:** High-level approach taken
  - **Files Modified/Created:** List all files with links and line numbers where applicable
  - **Implementation Details:** Technical specifics including code snippets, configuration changes, API integrations
  - **Results/Impact:** Measurable outcomes, performance improvements, UX enhancements
  - **Dependencies Added:** Any new packages with version numbers
  - **Testing/Build Status:** Confirmation that changes build successfully

• Update Frequency: Add summaries to the completion file immediately after finishing a feature or milestone. Do not batch updates - this ensures the documentation stays current and serves as a real-time progress tracker.

• Format Example: See PHASE3_COMPLETE.md for the standard format. Each feature should have:
  - Clear heading (## Feature Name)
  - Problem/Solution structure
  - Code examples with syntax highlighting
  - File references with clickable links (e.g., [filename](path/to/file.ts:123))
  - Visual indicators (✅ for completed, 🚧 for in-progress)

• Benefits: This practice ensures:
  - Historical record of what was completed and when
  - Easy onboarding for new team members or AI assistants
  - Clear demonstration of progress to stakeholders
  - Reference material for similar future implementations
  - Context preservation across long development sessions

Development Workflow & Automation
To maximize efficiency and consistency, we have a defined development workflow. This includes how to run and build the app, as well as techniques to automate repetitive tasks using scripts, aliases, and our AI helpers. Below are guidelines and tips for the development process:
• Running the App Locally: After cloning the repository and installing dependencies (npm install), you can start the development server with npm run dev. This launches the Vite dev server, usually at http://localhost:5173, with hot-reloading. During development, you’ll also need access to certain services:
• Make sure you have a local Ethereum node or testnet configuration if interacting with contracts (e.g., have a MetaMask wallet configured to Polygon Mumbai for testing, or run npx hardhat node if doing local Hardhat testing).
• If using SerpAPI live, ensure you have the API key in your .env (e.g., VITE_SERPAPI_KEY) and the dev server will proxy or include it appropriately. Alternatively, you might run a mock of the events API – e.g., serve a events.json from public for development to avoid using the API constantly.
• The dev server will compile and serve the React app, and any changes in src/ will hot-reload. Check the terminal for any compilation or lint errors and fix them as they arise. We treat warnings seriously as well – addressing those keeps the app clean.
• Building for Production: To generate an optimized build, run npm run build. This uses Vite to bundle the React app (minify JS/CSS, etc.) into a dist/ directory. You can then run npm run preview to test the production build locally. This step is also what Vercel does during deployment. Always test critical flows (like connecting a wallet, buying a test ticket) on the preview build to ensure no environment-specific issues. The build output will be used by Vercel to serve the app.
• Automation with NPM Scripts: We have defined several convenient NPM scripts in package.json:
• npm run dev – as mentioned, starts the dev server.
• npm run build – builds the app for production.
• npm run lint – runs ESLint across the codebase to check for coding standard violations.
• npm run format – runs Prettier to auto-format all files.
• npm run test – (if tests are added) executes the test suite.
• npm run deploy – (if configured) could be a shortcut to deploy the app (e.g., via Vercel CLI) from local.
Using these scripts simplifies common tasks so you don’t have to remember long commands. For example, instead of manually running a series of commands to deploy, a single npm run deploy could encompass build + test + vercel deploy steps. Always check package.json for the latest list of scripts available.
• Command Aliases for Productivity: To speed up repetitive command-line tasks, consider setting up shell aliases. For instance, if you find yourself frequently typing npm run dev, you can add an alias like alias dev="npm run dev" in your shell profile. Then simply typing dev will start the app. Similarly, you might alias npm run lint:fix as lintfix or nf. These aliases reduce keystrokes for common tasks and ensure you run the correct scripts each time (minimizing human error in typing long commands). They are especially useful for tasks you run dozens of times a day (starting/stopping the server, running tests, etc.). Developers on different OS/shells can adapt alias syntax as needed (e.g., using a Windows batch script or a Linux alias in .bashrc). The main idea is to automate anything you do frequently – for example, if deploying via CLI, alias the deploy command with all necessary flags. This optimization of workflow allows you to focus more on coding and less on typing commands.
• Utilizing AI Assistants in Development: Since we have powerful CLI-based AI coding assistants (Claude Code and OpenAI Codex), make them a part of your workflow:
• Pair Programming with AI: Treat the AI assistant like a teammate. For example, if you’re not sure how to implement a certain functionality, you can prompt Claude in natural language: “Help me write a React component that does X,” or “Refactor this function for better readability.” The key is to be specific and iterative. Provide the AI with sufficient context (you can paste in relevant code or refer to file names) and clearly state the requirements. Clear, detailed prompts lead to better outputs[30]. If the AI’s first answer isn’t perfect, refine your prompt or ask follow-up questions. Don’t hesitate to have a dialogue: e.g., “Explain why you chose this approach,” or “That wasn’t quite right, the component needs to do Y, not X.” Engaging in this back-and-forth yields the best results[31].
• Maintaining Quality Control: Even though the AI can generate code, you (the developer) are responsible for integrating and verifying it. Always review AI-generated code for correctness, security, and style. Ask the assistant to clarify any part of the code you don’t understand – for instance, “Can you comment this code and explain what each section does?” This can surface errors or assumptions. By treating the AI’s output as if it were a junior developer’s work, you ensure it meets the project’s standards. In fact, you can use the AI to double-check itself: after getting a snippet, prompt it with “Are there any potential bugs or edge cases in the above code?” This often reveals issues or improvements.
• Automating Repetitive Coding Tasks: Leverage the assistants to avoid boilerplate writing. If you need to create 5 similar components for different entities, you might do one manually and then ask Codex or Claude to generate the rest following the same pattern. The AI can quickly produce template code which you can fine-tune. Additionally, Claude Code (with Sonnet 4.5) is capable of performing multiple actions in one go. It can, for example, create a new file, update an existing file, and run a command concurrently as part of one task execution[32]. This means you could instruct, “Generate a new hook for fetching data and update the App component to use it, then run the tests,” and Claude might attempt to do all of that in sequence. While one should use such powerful autonomy carefully, it can speed up complex refactors or project-wide updates.
• Prompt Management: Keep a memory of successful prompts and even consider creating an AI Cheat Sheet file. For instance, document prompts that worked well (“Ask Claude to optimize a function by doing X”). This can be shared with the team so everyone benefits from effective techniques. Also, maintain awareness of the context window – feed the AI this instructions.md and relevant code when asking for help so it has full project understanding. Claude Code is designed to read and comprehend the entire repository context[33], and Codex CLI can be pointed at the project directory, so both can utilize the architecture and style info when generating code.
• Treat it as a Team Member: Ultimately, adopt a pair-programming mindset with AI – it works best when you collaborate rather than delegate blindly. Engage in a conversation: generate code, test it, discuss the outcomes with the AI, and iterate. This approach not only yields better code but also helps you learn and maintain a high-level understanding of the project (the AI might surface considerations you hadn’t thought of). The most productive sessions come from this interactive workflow of prompt -> review -> refine -> repeat, much like working with a human partner[31]. Remember that the AI can suggest design patterns or libraries too – feel free to ask its opinion (“Is there a better way to implement this feature?”) and then verify whatever it suggests.
• Continuous Integration (CI): (If set up) Commits to certain branches might trigger automated builds/tests (for example, via GitHub Actions or Vercel’s CI). Ensure that your changes pass all tests and lint checks before pushing. It’s good practice to run npm run lint && npm run test locally pre-push, or use a pre-push git hook, so that the CI will likely pass. This keeps our main branch stable.
By following this workflow and utilizing automation, we reduce manual effort and catch issues early. Simple steps like using aliases for shell commands, or asking the AI assistant to handle routine code, can save significant time. The combination of human insight with AI speed can be extremely powerful: for instance, an AI assistant can generate 10 variations of a function in seconds – but you choose the best one that fits. Always maintain that balance of speed and thoughtfulness.
Finally, keep documentation (like this guide) updated as the workflow evolves. If you add a useful alias or script, or discover a new best practice with the AI pair programmer, record it here so the whole team (and any new AI that reads the repo) can benefit. Development is an ongoing learning process, and we aim to continuously optimize it.
Deployment
Deploying the Unchained app (frontend and backend functions) is streamlined through Vercel. Below are the deployment instructions and considerations for launching the app to a live environment:
Vercel Deployment Process:
We use Vercel for hosting, which offers two main ways to deploy: 1. Deploy via Git (CI/CD): Our repository is linked to Vercel, so any push to the main branch (or a designated production branch) will trigger an automatic deployment[34]. Vercel’s Git integration will detect the React project (Vite) and use the correct build settings by default[35]. To set this up initially, one must: 2. Log in to Vercel and use the Import Project flow to connect the GitHub/GitLab/Bitbucket repository[34]. Choose the repo and branch, and Vercel will configure a project. 3. Define any needed environment variables in the Vercel dashboard (under Project Settings -> Environment Variables). For Unchained, this includes things like SERPAPI_API_KEY and any other API keys or secrets (these will be injected at build/runtime). 4. After linking, every code push results in Vercel building the app (npm install, then npm run build) and deploying it. Vercel provides preview URLs for each pull request and a production URL for the main branch[36]. 5. Once deployed, the app will be accessible at <project-name>.vercel.app by default, unless a custom domain is configured[37]. For example, if our project is named "unchained", it might live at unchained.vercel.app initially. 6. Deploy via Vercel CLI: For manual deployments or local testing of deployment, developers can use the Vercel CLI tool. Steps: 7. Install Vercel CLI globally: npm i -g vercel. Authenticate it (vercel login). 8. Run vercel in the project directory. The first time, it will prompt for some configuration (project name, which team/account, etc.). It generally auto-detects that this is a React/Vite app and applies appropriate defaults[35]. 9. The CLI will upload the project, run the build on Vercel’s servers, and give you a deployment URL (often a unique preview URL unless deploying to production explicitly). Use vercel --prod to force a production deployment on the main domain. 10. This method is useful if you want to deploy a feature branch temporarily or if you need to ensure something works in Vercel’s environment exactly as it does locally.
Environment & Configuration:
Before deploying, ensure that all required environment variables are set in Vercel. For Unchained, critical ones include: - SERPAPI_API_KEY – used by the backend or frontend to fetch event data. (If the fetching is done client-side, we might prefix it with VITE_ to embed during build. If serverless, just use it in the function.)

- Any API keys for blockchain RPC providers (e.g., an Infura project ID if we use one), or Thirdweb keys if applicable.
- If using a testnet (like Polygon Mumbai) for demo, environment variable might indicate which network or contract addresses to use (e.g., REACT*APP_NETWORK = mumbai). These should be set such that the build picks up the correct config.
  In local .env files, we mimic these values for testing. Remember not to commit real secrets; Vercel’s dashboard should hold the production secrets.
  Post-Deployment Testing:
  After deploying, it’s important to test the live site: - Open the Vercel deployment URL in a browser and click through the app. Verify that pages load without errors, and that blockchain interactions work (you might need a wallet connected to Polygon testnet for testing). - Check the console for any runtime errors. Sometimes environment-specific issues (like case-sensitive file paths on Vercel’s Linux environment, or missing env vars) can appear – fix those and redeploy if needed. - Test the serverless functions (if any). For instance, if we had an API route for events, try hitting https://yourapp.vercel.app/api/events to see if it returns expected data. Ensure CORS is okay if front-end calls back-end on the same domain (Vercel handles this generally by serving them from one domain).
  Custom Domain:
  If a custom domain is desired (e.g., unchained.com), go to Vercel settings and add the domain. Vercel will guide DNS configuration (adding CNAME records). Once set, the app will be accessible at the custom domain, and Vercel will provision SSL automatically. This doesn’t change how we deploy, it just changes where the live site resides.
  Deployment of Smart Contracts:
  This is somewhat separate from Vercel (which covers the web app). For the blockchain aspect: - If deploying new versions of the NFT ticket smart contract, you’d use Hardhat or Thirdweb CLI. This might involve running npx hardhat deploy --network polygon or using the Thirdweb dashboard to deploy a contract. Keep track of contract addresses and update the frontend config if they change. - We might maintain a file like src/constants/contracts.js that holds the addresses/ABIs of deployed contracts. When deploying to mainnet or testnet, update those accordingly and redeploy the frontend so it knows where to interact.
  Monitoring and Logs:
  Vercel provides a “Functions” tab where you can see logs from serverless function executions. If our app has any backend code (e.g., an API route that fetches from SerpAPI or interacts with blockchain via Node), we can check those logs for errors (in Vercel’s dashboard or via vercel logs). Additionally, if using external logging or tracking (Sentry, LogRocket), ensure they are capturing events in production.
  Scaling Considerations:
  Vercel will automatically scale the static front-end globally on its Edge network. The serverless functions scale per request (cold starts might happen if low traffic). Given our app is read-heavy (users browsing events) and write-light (minting tickets occasionally), Vercel should handle this well. If we anticipate very high traffic for a big on-sale event, we might need to consider performance (e.g., caching event data or using a queue for mint transactions). At our current stage, Vercel’s default setup is sufficient.
  Summary of Deployment Steps:
  For clarity, a concise step-by-step for a fresh deployment is: 1. Preparation: Commit all changes and ensure npm run build passes locally. Set environment variables on VerUnchained – Project Overview & Developer Guide
  Overview
  Project Goals & Problem Statement:
  Unchained is a decentralized ticketing platform built to disrupt the monopoly of traditional event ticketing (e.g. combating Ticketmaster-like control). It leverages blockchain technology to eliminate counterfeit tickets, prevent scalping, reward loyal fans, and empower the community of artists and attendees[1]. In today’s ticketing industry, users face rampant fraud and price gouging by resellers; artists and venues lose control over secondary sales. Unchained addresses these issues by ensuring fairness, transparency, and fan rewards through smart contracts[2]. Its mission-driven approach aims to create a transparent, fan-first ecosystem free from monopolistic control[3].
  Core Functionality:
  Unchained issues event tickets as NFTs (non-fungible tokens) on the blockchain, enforcing authenticity and programmable resale rules. Key features of the platform include:
  • NFT Ticketing with Royalties: Event tickets are minted as ERC-721 NFTs, optionally with ERC-2981 royalty standards so that organizers or artists get a cut from any resale[4]. Smart contracts automatically prevent scalping by capping resale prices or enforcing royalties on secondary transfers[4]. This ensures tickets cannot be easily flipped for profit without benefiting the content creators.
  • Authenticity & Anti-Fraud: Because each ticket is a unique token on the blockchain, it’s impossible to counterfeit. Venues can easily verify on-chain that a ticket is genuine, eliminating fake tickets and fraud at entry[1].
  • Collectible Ticket Stubs: After an event, the NFT ticket serves as a digital collectible (souvenir) for the fan[5]. Fans can keep or trade these NFT ticket stubs, which might unlock future perks. This builds a sense of community and rewards fandom beyond the event itself.
  • Analytics & Dashboards: The platform provides dashboards for venues and artists[6]. Organizers can see real-time data on ticket ownership, transfers, and attendance. This actionable analytics information (e.g. how many tickets were resold, fan demographics, etc.) helps them make informed decisions for future events.
  • Fan Loyalty & Rewards: A built-in loyalty system rewards fans for attending events and holding tickets[6]. For example, fans might earn tokens or exclusive access to merchandise and presales after attending multiple events. This encourages genuine fans to participate and remain engaged.
  • Event Discovery & Community: Users can search for events, venues, or artists via a discovery interface with fuzzy search[7]. A landing page (“Join The Resistance”) acts as a waitlist/signup funnel for early adopters[8], reflecting the project’s punk/activist branding. This helps build a community and user base before full launch.
  Overall, Unchained’s target audience includes music fans (who want authentic tickets and collectible experiences), artists (who seek fair royalties and direct fan engagement), and venues (needing fraud prevention and better analytics)[9]. By aligning the interests of these groups, the platform strives to create a fairer, more transparent ticketing ecosystem powered by blockchain.
  Tech Stack
  This project uses a modern web and blockchain stack. Below is an overview of all major technologies, libraries, and frameworks used (with versions where applicable):
  • Frontend: React (v18+) single-page application, bootstrapped with Vite for fast builds and dev server[10]. The UI is styled using Tailwind CSS (v3) along with custom CSS modules for unique design elements. Routing is handled by React Router (v6+).
  • Backend: Node.js (v18 LTS) powers any server-side logic. The app uses a lightweight Express (v4) server for API endpoints, which in production is deployed as serverless functions on Vercel. This means each API route runs as a standalone cloud function, enabling scalable on-demand backend execution.
  • Blockchain & Smart Contracts: The platform is built on the Ethereum Virtual Machine (EVM) ecosystem, specifically targeting the Polygon network (a cost-effective Ethereum L2) for deploying smart contracts[10]. Smart contracts are written in Solidity and managed using Hardhat (2.x) during development[11]. We also leverage Thirdweb SDK/tools for quick contract deployment and management as needed[12]. The NFT ticket contract implements standards like ERC-721 for tokens and ERC-2981 for royalties.
  • Web3 Integration: On the client side, we use the ethers.js library and Wagmi React hooks (v0.x or v1) for blockchain interactions. RainbowKit and the Coinbase Wallet SDK are integrated to provide a smooth wallet connection UI. This allows users to connect with MetaMask, Coinbase Wallet, or others to purchase and hold their NFT tickets. The Coinbase Onchain Kit is explored as well – it offers pre-built components and utilities for building on-chain user experiences (particularly useful if integrating with Coinbase’s Base network or account abstraction features).
  • Storage: Event and ticket metadata (images, descriptions) are stored off-chain using decentralized storage. We utilize NFT.Storage (an IPFS pinning service) to store media and JSON metadata on IPFS (InterPlanetary File System). This ensures that ticket details and artwork remain publicly accessible and tamper-proof.
  • Search: For client-side searching and fuzzy matching through events, artists, or venues, we include Fuse.js. This lightweight library enables substring and approximate text matching to improve the user’s ability to find events (e.g., searching by partial artist name or venue).
  • Hosting & Deployment: The application is hosted on Vercel, which provides an all-in-one platform for static frontends and API functions. Vercel is connected to our Git repository for continuous deployment; every push to main triggers a rebuild and redeploy. (See Deployment section for details.)
  • Developer Tooling (AI Assistants): To boost productivity, the team leverages AI coding assistants in the development workflow. Notably, we use Anthropic’s Claude Code (powered by the Claude Sonnet 4.5 model) and OpenAI’s Codex CLI:
  • Claude Code (Sonnet 4.5): An advanced AI pair-programming assistant by Anthropic. Claude Code can understand the entire project repository context and provide intelligent code suggestions, refactorings, and even generate new files based on natural language instructions[13]. Sonnet 4.5 is the underlying model that grants Claude Code extended autonomous coding capabilities, allowing it to handle long coding sessions and complex tasks with improved reasoning[14]. In practice, we use Claude in the CLI/IDE to help write boilerplate, find bugs, and accelerate development.
  • OpenAI Codex CLI: An AI coding agent from OpenAI that runs locally in the terminal[15]. Codex CLI can interpret commands or prompts and directly modify code or execute tasks. It’s essentially an AI that can take shell instructions and code context to assist with implementations. We use Codex for on-demand code generation and to automate repetitive coding tasks through the command line.
  By combining this tech stack, Unchained delivers a full-stack DApp (Decentralized Application) experience: a React/Tailwind UI, a Node/Vercel serverless backend, and smart contracts on Polygon, all integrated seamlessly. The inclusion of AI coding tools (Claude and Codex) is also an innovative part of our development process, enabling faster and smarter coding.
  Project Structure
  The repository follows a structured layout to organize source code and assets. Below is an outline of the core project folders and files, with explanations for each:
  • src/assets/ – Contains static assets like images, icons, and texture files used in the app. For example, background images or logo files referenced in components would reside here.
  • src/components/ – Reusable UI components for the React frontend. These are usually small, self-contained pieces of the interface (buttons, cards, navigation items, etc.) that can be composed to build pages. For instance, EventCard.jsx displays a summary of an event (with image, title, date) and is used across different pages.
  • src/pages/ – Page-level components representing different screens or routes in the application. Each page might import many components. Examples include Home.jsx, EventDetail.jsx, or TicketView.jsx. Pages correspond to routes in the React Router configuration.
  • src/utils/ – Utility modules and helper functions. These contain non-React logic that can be reused across the app. For example, a slugify.js for creating URL-friendly strings from event names[16], an openGoogleMaps.js to abstract opening external map links, or other data processing helpers. Placing these in utils keeps components cleaner and promotes reuse.
  • src/styles/ – All styling files (CSS) are organized here. We use a combination of Tailwind CSS utility classes and custom CSS. The styles folder is further subdivided for maintainability:
  • styles/base/ – Global base styles such as resets (e.g. \_reset.css), typography defaults (\_typography.css), and general global rules (\_globals.css for things like box-sizing, element defaults)[17]. These are loaded first to establish a baseline.
  • styles/tokens/ – Design tokens and variables, e.g. \_colors.css defining the central color palette, \_spacing.css for spacing scale (margin/padding sizes), \_typescale.css for font sizes and line-heights[18]. By defining these in one place, we ensure consistency (the values here correspond to the brand style guide).
  • styles/components/ – Component-specific CSS classes. For example, button.css contains styles for the custom button styles used in the app, input.css for form elements, card.css for card components like event cards[19]. These are imported by the corresponding JSX components or by the main CSS.
  • styles/layout/ – Layout helpers, such as grid.css (common grid or flexbox utilities) and containers.css (max-widths for containers, layout structure)[20].
  • styles/index.css – The main stylesheet that imports all the other CSS files in the correct order[21]. This is the file ultimately loaded by the app to apply all styles.
  • src/App.jsx – The root React component that defines the overall application structure and routing. This typically includes the Router setup (mapping URL paths to the components in pages/), as well as any global context providers (for theme, authentication, API data, etc.). It can be thought of as the “controller” of the frontend. [22]
  • src/main.jsx – The entry point for the React application. This is where we mount the App component onto the DOM. Vite uses this as the bootstrap file. It usually contains something like ReactDOM.createRoot(...).render(<App />). (If we were using TypeScript or advanced configurations, this is also where HMR and strict mode might be set up.)[22]
  • (Potential) src/api/ – In a full-stack project on Vercel, we might have an api/ directory for serverless function files (e.g., src/api/checkout.js for a ticket purchase endpoint). In this project, API calls for event data might instead be handled client-side (for example, fetching from SerpAPI directly in the frontend), so an api/ folder may not be present. If future backend functions are needed (like a custom endpoint), this is where they would live, and Vercel would deploy them automatically.
  • Other config files – The project root includes typical configuration files: package.json (npm dependencies and scripts), possibly .eslintrc.json or .prettierrc (for linting/format rules), and smart contract directories if any (e.g., a contracts/ folder or Hardhat config if Solidity code is present). There’s also a README.md which provides high-level info (much of which is reflected in this guide).
  This structure groups related files together, making the project maintainable and scalable. For instance, all UI components are in one place, styles are centralized, and utilities are separated from React components. The layout shown above is drawn from the project’s architecture documentation[23][24], ensuring that anyone reading this guide or using an AI assistant on the repo has a clear map of where things are.
  Coding Standards
  We adhere to consistent coding conventions and best practices to maintain code quality and readability. Below are the style guidelines, linting rules, and design patterns followed in the Unchained project:
  • Code Style & Formatting: We use Prettier as an automated code formatter across the project. All code should be formatted with Prettier’s default conventions (2-space indentation, semicolons, quotes, etc.) on save or before commit. Prettier ensures that the entire codebase has a consistent style, automatically reprinting code in a unified format[25]. This eliminates debates over styling – developers can focus on logic, and the formatter takes care of spacing, line breaks, and so on. (Prettier is widely considered an industry-standard tool for JS formatting, and using it helps us follow common best practices out-of-the-box.) We also encourage using an editor integration for Prettier or a pre-commit hook, so that code is always formatted correctly.
  • Linting & Best Practices: In addition to formatting, we enforce code quality via ESLint. The project is configured (or plans to be configured) with an ESLint setup – likely extending a well-known style guide such as Airbnb or using eslint:recommended with Prettier integration. The linter will catch common bugs or anti-patterns (unused variables, undefined variables, improper React hook usage, etc.). All team members (and AI assistants) should ensure code passes lint checks. For example, follow naming conventions: use camelCase for variables/functions, PascalCase for React components, and UPPER_SNAKE_CASE for constants. Prefer const and let over var, and use ES6+ syntax (arrow functions, spread operators, template strings) for cleaner, modern JavaScript.
  • Project Patterns: We follow a component-driven architecture in React. That means keeping components focused and reusable. Functional components (with hooks) are used exclusively (no legacy class components). Related to that, React hooks are used for stateful logic and side effects – e.g., a custom hook useFuseSearch encapsulates search logic[26], and Context API is used for global state like events data (see APIContext usage in components). This pattern keeps view components (pages and UI elements) declarative and offloads data fetching or logic to hooks and context providers.
  • UI/UX Consistency: All UI elements and styling follow the design system outlined in our Style Guide. Developers should use the predefined CSS classes (from styles/) and Tailwind utilities instead of arbitrary new styles, to maintain consistency. For example, use the color variables and spacing scales defined in styles/tokens/\_colors.css and \_spacing.css rather than hardcoding hex colors or pixel values. The “punk/underground” aesthetic (gritty textures, neon accents) described in the style guide should be reflected in the components – e.g., using the Resistance Red and Toxic Neon colors for call-to-action elements as specified. When in doubt, refer to Unchained Style Guide for visual guidelines on components like buttons, cards, etc. This ensures the app’s look stays unified.
  • Accessibility: We prioritize building an accessible application. Follow ARIA and accessibility best practices: use semantic HTML elements where possible (e.g., <button> for clickable actions, <nav> for navigation regions), and add ARIA labels/roles for custom components. All interactive elements must be reachable via keyboard (tab navigation) and provide visual focus states. We also ensure sufficient color contrast in text and UI (meeting WCAG AA standards)[27]. For example, the design palette was chosen with contrast in mind and developers should not deviate in ways that reduce readability. Any image must have an alt attribute describing it (especially important if the image conveys info). By adhering to these, we make the app usable for as many people as possible.
  • Git & Commit Conventions: (If applicable) We follow a conventional commit style or at least clear commit messages. When using the AI assistants for generating code, it’s still the developer’s job to summarize changes in commit messages for clarity. Feature branches and pull requests should be used for major features, with code reviews (even if AI-generated code) to maintain quality.
  • Testing & QA: (Planned) Testing is crucial especially with AI-generated code. We intend to write unit tests (perhaps using Jest or Vitest) for critical functions like smart contract interactions or utility functions. Test files would mirror the structure (e.g., utils/slugify.test.js). Ensure new code is covered by tests where feasible. Even if not fully in place yet, developers should manually test features (e.g., actually attempt an NFT purchase in a test environment, or run through the ticket redemption flow) to validate that everything works as expected.
  In summary, code contributors (human or AI) should produce clean, readable code that aligns with the established style. Prettier handles the micro-formatting, while developers must enforce logical consistency and project conventions. By following these standards, we ensure the codebase remains maintainable and coherent as the project grows.
  User Stories
  To understand the platform’s features from an end-user perspective, here are key user stories categorized by user type (fan, artist/organizer, venue). These stories illustrate what each type of user can achieve with Unchained, and they reflect the platform’s core value propositions:
  • As a Music Fan (Ticket Buyer): I want to discover upcoming events easily and buy authentic tickets with confidence. Using Unchained, I can search for events or artists and purchase a ticket as an NFT directly from the official source. This guarantees that my ticket is not counterfeit and I won’t be scammed at the door. After the event, I still hold the NFT as a digital collectible stub, which might grant me exclusive content or just serve as a memorable keepsake. I also enjoy loyalty rewards for using the platform – for example, being a repeat attendee could unlock special perks or early access to future tickets. (Target outcome: fans get legitimate tickets and added value like collectibles and rewards, addressing their desire for authentic access and a closer connection to the experience[28].)
  • As an Avid Fan (Resale Participant): I want the ability to resell my ticket if I can’t attend, but in a fair way. On Unchained, if I list my NFT ticket for resale, the platform’s smart contract might enforce a price cap or automatically include a royalty. This means I can recoup my cost (or a modest profit) but cannot scalp the ticket at exorbitant prices, keeping things fair for other fans. I’m okay with this because it also means if I’m buying a resold ticket, I won’t have to pay an outrageous markup – the system protects me either way. Plus, any resale royalty might go to the artist or event organizer, supporting them rather than just profiteers.
  • As an Event Organizer/Artist: I want control over my event’s ticketing and to ensure true fans get access. With Unchained, I can mint a fixed number of NFT tickets for my event and sell them directly to fans without middleman platforms taking a huge cut. I can set rules like “tickets cannot be resold above face value” or “I receive 10% of any resale via royalty.” This guarantees that scalpers cannot exploit my tickets, and if they do resell, I share in the upside[28]. I also get a dashboard that shows who my top fans are (e.g., someone who holds many of my event NFTs) and I can reward them with special NFTs or experiences. After the show, I know each ticket NFT’s holder – this opens up new marketing opportunities like airdropping a thank-you token or offering discount codes to those who attended. Essentially, I gain actionable insights and a direct relationship with my audience that wasn’t possible with traditional ticketing.
  • As a Venue Manager: I need to ensure smooth entry and eliminate fraud at the gate. Using Unchained’s system, my team can scan a ticket’s QR code or wallet at entry and instantly verify on the blockchain that it’s a valid ticket that hasn’t been used before. This gives us confidence that no fake tickets will slip through[1], avoiding any confrontation with fans holding bogus tickets. The entry process becomes quicker and more secure. Additionally, I can see analytics on attendance: because each NFT ticket is traceable, I can know how many people transferred their tickets, how many checked in, etc. Over time, this helps with planning (for instance, identifying that a certain percentage of tickets always get resold might inform pricing or security measures). The data and fraud prevention together provide a better experience for both staff and attendees[9].
  • As a New User (Waitlist Member): I am interested in the concept and want to join the platform early. I can sign up on the “Join The Resistance” waitlist page. As a member of the waitlist or early adopter, I might receive updates, beta access, or even an NFT badge that labels me as part of the founding community. This makes me feel involved in the movement to change ticketing. When the next big event is announced, I’ll be among the first notified so I can snag my NFT ticket and not miss out.
  Each of these stories highlights how Unchained provides benefits to its stakeholders. Fans get authenticity, collectibles, and fair prices; artists get fairness, royalties, and engagement; venues get security and insights. These align closely with the project’s mission and target audience needs (fans seeking authentic access and collectibles, artists wanting fair royalties & direct engagement, venues needing fraud prevention & analytics)[9]. As development continues, we will expand on these stories, ensuring the implemented features satisfy the underlying user needs.
  APIs and Integrations
  Unchained integrates with several external services and platforms to deliver its functionality. Here’s an overview of key APIs and third-party integrations and how they connect to our system:
  • Blockchain Network (Polygon): All NFT tickets and smart contracts are deployed on the Polygon blockchain (an EVM-compatible network). We connect to Polygon via standard RPC endpoints (e.g., Infura or Alchemy may be used under the hood, though not explicitly mentioned). The ethers.js library and Wagmi hooks handle the low-level interaction (sending transactions, reading contract state). From the app’s perspective, when a user buys a ticket, a transaction is sent to the Polygon network which mints the NFT to their wallet. Similarly, checking ticket validity at event time involves reading the NFT’s ownership from the blockchain. This integration is fundamental – the decentralized ledger is what provides security and transparency.
  • Wallet Connectivity (RainbowKit & Coinbase Wallet): The app integrates RainbowKit (a popular React library for wallet connections) along with Coinbase Wallet SDK for an optimal multi-wallet support. This means users can click “Connect Wallet” and use MetaMask, Coinbase Wallet, WalletConnect, etc. RainbowKit provides a polished UI modal for selecting and connecting wallets, while Coinbase’s SDK ensures compatibility and a seamless link to Coinbase’s user base. This integration abstracts a lot of Web3 complexity and provides a secure way for users to sign transactions (e.g., when purchasing a ticket NFT).
  • Coinbase OnchainKit: This is a newer toolkit by Coinbase (especially for the Base L2 chain) that provides components and utilities for on-chain app development. While not fully implemented yet, we plan to leverage OnchainKit for features like gasless transactions or simplified contract integration if deploying on Coinbase’s Base network. For example, OnchainKit’s account abstraction might allow Unchained to sponsor gas fees for first-time users (making it easier for non-crypto-savvy fans to use the platform). It can also offer standardized components for transaction flows. This integration is exploratory but could enhance user experience by reducing blockchain friction.
  • SerpAPI (Google Events API): During development (and possibly in production for event data aggregation), Unchained uses SerpAPI to fetch event listings from Google’s Events results. SerpAPI is a scraping API that can query Google for events in a given location or query. We integrate this to populate our app with sample events and details (title, date, venue, event link, etc.) without having our own events database initially. The API is used server-side or client-side with an API key. For example, on the homepage, the app might call our backend (or directly SerpAPI) to get “Concerts in New York this week” and display them. We have a SerpAPI key set up (see configuration) that allows a certain number of calls per month. In development, we often mock or cache this data to avoid hitting rate limits.
  • NFT.Storage / IPFS: For storing metadata like event descriptions, images, or even the minted ticket stub images, we use NFT.Storage which is built on IPFS. When an organizer creates a new event ticket NFT, an JSON metadata file (containing fields like name, description, image URL, event date) is uploaded to IPFS via NFT.Storage, returning a content hash (CID). That CID is then referenced in the NFT’s metadata URI. The integration with NFT.Storage is through its API – we send an HTTP request with the file or JSON, and get back an IPFS link. This ensures media content for tickets is distributed and not reliant on a single server. Users retrieving their ticket info load it from IPFS, which is decentralized.
  • Analytics and Tracking: (Planned integration) We may use services like Google Analytics or a Web3 analytics tool to understand user behavior on the DApp. However, given the privacy-conscious ethos of blockchain communities, we will be cautious with tracking. If used, it might be an anonymized page view tracker or something like Vercel Analytics for performance monitoring[29]. This helps us see how the app performs and which features are most used, guiding further development.
  • Email/Notification Service: (Future integration) To manage the waitlist and user communications, an integration with an email service (like SendGrid or Mailchimp) might be utilized. For example, when a user joins the waitlist (inputs their email on “JoinTheResistance” page), we store that and possibly send a confirmation or periodic newsletter. This would involve either a small backend function hitting an email API or a third-party automation. Not implemented yet but foreseen.
  • Payment Gateway (Fiat to Crypto): One challenge is enabling users who don’t hold cryptocurrency to buy NFT tickets. We are considering integrating a service like Coinbase Pay or MoonPay – something that can handle fiat-to-crypto seamlessly. This would allow a user with just a credit card to purchase an NFT ticket, with the service handling the backend conversion and minting. This integration would be important to onboard mainstream users, though it comes with KYC and regulatory overhead. At the moment, users are expected to have a crypto wallet and MATIC/ETH for gas, but this is an area for improvement.
  Each of these integrations plays a role in the overall system. For instance, SerpAPI provides the event content that makes the app immediately useful; Polygon blockchain provides the trust and enforcement for tickets; wallet integrations provide usability for Web3; and NFT.Storage ensures decentralized persistence of data. We’ve designed the system such that if any integration is unavailable (say SerpAPI rate limit exceeded), the app fails gracefully (e.g., show cached events or a message). Environment variables and config files store API keys and IDs securely (e.g., the SerpAPI key is stored in .env and set in Vercel config, not hardcoded).
  By using established services and APIs, we avoid re-inventing the wheel and can focus on our unique logic. All external integrations are documented so that developers (and AI assistants) understand how to call them. For example, developers can consult SerpAPI’s docs to format queries (the integration is straightforward: a REST GET request with our key and query parameters). The Tech Stack table in our README also summarizes many of these connections (e.g., wagmi for Web3, Vercel for hosting, etc.).
  Development Workflow & Automation
  To maximize efficiency and consistency, we have a defined development workflow. This includes how to run and build the app, as well as techniques to automate repetitive tasks using scripts, aliases, and our AI helpers. Below are guidelines and tips for the development process:
  • Running the App Locally: After cloning the repository and installing dependencies (npm install), you can start the development server with npm run dev. This launches the Vite dev server, usually at http://localhost:5173, with hot-reloading. During development, you’ll also need access to certain services:
  • Make sure you have a local Ethereum node or testnet configuration if interacting with contracts (e.g., have a MetaMask wallet configured to Polygon Mumbai for testing, or run npx hardhat node if doing local Hardhat testing).
  • If using SerpAPI live, ensure you have the API key in your .env (e.g., VITE_SERPAPI_KEY) and the dev server will proxy or include it appropriately. Alternatively, you might run a mock of the events API – e.g., serve a events.json from public for development to avoid using the API constantly.
  • The dev server will compile and serve the React app, and any changes in src/ will hot-reload. Check the terminal for any compilation or lint errors and fix them as they arise. We treat warnings seriously as well – addressing those keeps the app clean.
  • Building for Production: To generate an optimized build, run npm run build. This uses Vite to bundle the React app (minify JS/CSS, etc.) into a dist/ directory. You can then run npm run preview to test the production build locally. This step is also what Vercel does during deployment. Always test critical flows (like connecting a wallet, buying a test ticket) on the preview build to ensure no environment-specific issues. The build output will be used by Vercel to serve the app.
  • Automation with NPM Scripts: We have defined several convenient NPM scripts in package.json:
  • npm run dev – as mentioned, starts the dev server.
  • npm run build – builds the app for production.
  • npm run lint – runs ESLint across the codebase to check for coding standard violations.
  • npm run format – runs Prettier to auto-format all files.
  • npm run test – (if tests are added) executes the test suite.
  • npm run deploy – (if configured) could be a shortcut to deploy the app (e.g., via Vercel CLI) from local.
  Using these scripts simplifies common tasks so you don’t have to remember long commands. For example, instead of manually running a series of commands to deploy, a single npm run deploy could encompass build + test + vercel deploy steps. Always check package.json for the latest list of scripts available.
  • Command Aliases for Productivity: To speed up repetitive command-line tasks, consider setting up shell aliases. For instance, if you find yourself frequently typing npm run dev, you can add an alias like alias dev="npm run dev" in your shell profile. Then simply typing dev will start the app. Similarly, you might alias npm run lint:fix as lintfix or nf. These aliases reduce keystrokes for common tasks and ensure you run the correct scripts each time (minimizing human error in typing long commands). They are especially useful for tasks you run dozens of times a day (starting/stopping the server, running tests, etc.). Developers on different OS/shells can adapt alias syntax as needed (e.g., using a Windows batch script or a Linux alias in .bashrc). The main idea is to automate anything you do frequently – for example, if deploying via CLI, alias the deploy command with all necessary flags. This optimization of workflow allows you to focus more on coding and less on typing commands.
  • Utilizing AI Assistants in Development: Since we have powerful CLI-based AI coding assistants (Claude Code and OpenAI Codex), make them a part of your workflow:
  • Pair Programming with AI: Treat the AI assistant like a teammate. For example, if you’re not sure how to implement a certain functionality, you can prompt Claude in natural language: “Help me write a React component that does X,” or “Refactor this function for better readability.” The key is to be specific and iterative. Provide the AI with sufficient context (you can paste in relevant code or refer to file names) and clearly state the requirements. Clear, detailed prompts lead to better outputs[30]. If the AI’s first answer isn’t perfect, refine your prompt or ask follow-up questions. Don’t hesitate to have a dialogue: e.g., “Explain why you chose this approach,” or “That wasn’t quite right, the component needs to do Y, not X.” Engaging in this back-and-forth yields the best results[31].
  • Maintaining Quality Control: Even though the AI can generate code, you (the developer) are responsible for integrating and verifying it. Always review AI-generated code for correctness, security, and style. Ask the assistant to clarify any part of the code you don’t understand – for instance, “Can you comment this code and explain what each section does?” This can surface errors or assumptions. By treating the AI’s output as if it were a junior developer’s work, you ensure it meets the project’s standards. In fact, you can use the AI to double-check itself: after getting a snippet, prompt it with “Are there any potential bugs or edge cases in the above code?” This often reveals issues or improvements.
  • Automating Repetitive Coding Tasks: Leverage the assistants to avoid boilerplate writing. If you need to create 5 similar components for different entities, you might do one manually and then ask Codex or Claude to generate the rest following the same pattern. The AI can quickly produce template code which you can fine-tune. Additionally, Claude Code (with Sonnet 4.5) is capable of performing multiple actions in one go. It can, for example, create a new file, update an existing file, and run a command concurrently as part of one task execution[32]. This means you could instruct, “Generate a new hook for fetching data and update the App component to use it, then run the tests,” and Claude might attempt to do all of that in sequence. While one should use such powerful autonomy carefully, it can speed up complex refactors or project-wide updates.
  • Prompt Management: Keep a memory of successful prompts and even consider creating an AI Cheat Sheet file. For instance, document prompts that worked well (“Ask Claude to optimize a function by doing X”). This can be shared with the team so everyone benefits from effective techniques. Also, maintain awareness of the context window – feed the AI this instructions.md and relevant code when asking for help so it has full project understanding. Claude Code is designed to read and comprehend the entire repository context[33], and Codex CLI can be pointed at the project directory, so both can utilize the architecture and style info when generating code.
  • Treat it as a Team Member: Ultimately, adopt a pair-programming mindset with AI – it works best when you collaborate rather than delegate blindly. Engage in a conversation: generate code, test it, discuss the outcomes with the AI, and iterate. This approach not only yields better code but also helps you learn and maintain a high-level understanding of the project (the AI might surface considerations you hadn’t thought of). The most productive sessions come from this interactive workflow of prompt -> review -> refine -> repeat, much like working with a human partner[31]. Remember that the AI can suggest design patterns or libraries too – feel free to ask its opinion (“Is there a better way to implement this feature?”) and then verify whatever it suggests.
  • Continuous Integration (CI): (If set up) Commits to certain branches might trigger automated builds/tests (for example, via GitHub Actions or Vercel’s CI). Ensure that your changes pass all tests and lint checks before pushing. It’s good practice to run npm run lint && npm run test locally pre-push, or use a pre-push git hook, so that the CI will likely pass. This keeps our main branch stable.
  By following this workflow and utilizing automation, we reduce manual effort and catch issues early. Simple steps like using aliases for shell commands, or asking the AI assistant to handle routine code, can save significant time. The combination of human insight with AI speed can be extremely powerful: for instance, an AI assistant can generate 10 variations of a function in seconds – but you choose the best one that fits. Always maintain that balance of speed and thoughtfulness.
  Finally, keep documentation (like this guide) updated as the workflow evolves. If you add a useful alias or script, or discover a new best practice with the AI pair programmer, record it here so the whole team (and any new AI that reads the repo) can benefit. Development is an ongoing learning process, and we aim to continuously optimize it.
  Deployment
  Deploying the Unchained app (frontend and backend functions) is streamlined through Vercel. Below are the deployment instructions and considerations for launching the app to a live environment:
  Vercel Deployment Process:
  We use Vercel for hosting, which offers two main ways to deploy: 1. Deploy via Git (CI/CD): Our repository is linked to Vercel, so any push to the main branch (or a designated production branch) will trigger an automatic deployment[34]. Vercel’s Git integration will detect the React project (Vite) and use the correct build settings by default[35]. To set this up initially, one must: 2. Log in to Vercel and use the Import Project flow to connect the GitHub/GitLab/Bitbucket repository[34]. Choose the repo and branch, and Vercel will configure a project. 3. Define any needed environment variables in the Vercel dashboard (under Project Settings -> Environment Variables). For Unchained, this includes things like SERPAPI_API_KEY and any other API keys or secrets (these will be injected at build/runtime). 4. After linking, every code push results in Vercel building the app (npm install, then npm run build) and deploying it. Vercel provides preview URLs for each pull request and a production URL for the main branch[36]. 5. Once deployed, the app will be accessible at <project-name>.vercel.app by default, unless a custom domain is configured[37]. For example, if our project is named "unchained", it might live at unchained.vercel.app initially. 6. Deploy via Vercel CLI: For manual deployments or local testing of deployment, developers can use the Vercel CLI tool. Steps: 7. Install Vercel CLI globally: npm i -g vercel. Authenticate it (vercel login). 8. Run vercel in the project directory. The first time, it will prompt for some configuration (project name, which team/account, etc.). It generally auto-detects that this is a React/Vite app and applies appropriate defaults[35]. 9. The CLI will upload the project, run the build on Vercel’s servers, and give you a deployment URL (often a unique preview URL unless deploying to production explicitly). Use vercel --prod to force a production deployment on the main domain. 10. This method is useful if you want to deploy a feature branch temporarily or if you need to ensure something works in Vercel’s environment exactly as it does locally.
  Environment & Configuration:
  Before deploying, ensure that all required environment variables are set in Vercel. For Unchained, critical ones include: - SERPAPI_API_KEY – used by the backend or frontend to fetch event data. (If the fetching is done client-side, we might prefix it with VITE* to embed during build. If serverless, just use it in the function.)
- Any API keys for blockchain RPC providers (e.g., an Infura project ID if we use one), or Thirdweb keys if applicable.
- If using a testnet (like Polygon Mumbai) for demo, environment variable might indicate which network or contract addresses to use (e.g., REACT_APP_NETWORK = mumbai). These should be set such that the build picks up the correct config.
  In local .env files, we mimic these values for testing. Remember not to commit real secrets; Vercel’s dashboard should hold the production secrets.
  Post-Deployment Testing:
  After deploying, it’s important to test the live site: - Open the Vercel deployment URL in a browser and click through the app. Verify that pages load without errors, and that blockchain interactions work (you might need a wallet connected to Polygon testnet for testing). - Check the console for any runtime errors. Sometimes environment-specific issues (like case-sensitive file paths on Vercel’s Linux environment, or missing env vars) can appear – fix those and redeploy if needed. - Test the serverless functions (if any). For instance, if we had an API route for events, try hitting https://yourapp.vercel.app/api/events to see if it returns expected data. Ensure CORS is okay if front-end calls back-end on the same domain (Vercel handles this generally by serving them from one domain).
  Custom Domain:
  If a custom domain is desired (e.g., unchained.com), go to Vercel settings and add the domain. Vercel will guide DNS configuration (adding CNAME records). Once set, the app will be accessible at the custom domain, and Vercel will provision SSL automatically. This doesn’t change how we deploy, it just changes where the live site resides.
  Deployment of Smart Contracts:
  This is somewhat separate from Vercel (which covers the web app). For the blockchain aspect: - If deploying new versions of the NFT ticket smart contract, you’d use Hardhat or Thirdweb CLI. This might involve running npx hardhat deploy --network polygon or using the Thirdweb dashboard to deploy a contract. Keep track of contract addresses and update the frontend config if they change. - We might maintain a file like src/constants/contracts.js that holds the addresses/ABIs of deployed contracts. When deploying to mainnet or testnet, update those accordingly and redeploy the frontend so it knows where to interact.
  Monitoring and Logs:
  Vercel provides a “Functions” tab where you can see logs from serverless function executions. If our app has any backend code (e.g., an API route that fetches from SerpAPI or interacts with blockchain via Node), we can check those logs for errors (in Vercel’s dashboard or via vercel logs). Additionally, if using external logging or tracking (Sentry, LogRocket), ensure they are capturing events in production.
  Scaling Considerations:
  Vercel will automatically scale the static front-end globally on its Edge network. The serverless functions scale per request (cold starts might happen if low traffic). Given our app is read-heavy (users browsing events) and write-light (minting tickets occasionally), Vercel should handle this well. If we anticipate very high traffic for a big on-sale event, we might need to consider performance (e.g., caching event data or using a queue for mint transactions). At our current stage, Vercel’s default setup is sufficient.
  Summary of Deployment Steps:
  For clarity, a concise step-by-step for a fresh deployment is: 1. Preparation: Commit all changes and ensure npm run build passes locally. Set environment variables on Vercel dashboard (one-time setup).

2. Trigger Deploy: Either push to the main branch if CI is configured, or run vercel --prod using the CLI.
3. Vercel Build: Vercel will detect the project and run the build (React app) and package serverless functions. No manual config needed in most cases[38].
4. Verification: Once deployed, access the live URL. Test the application’s main functionalities (connect wallet, view events, etc.) on the live site.
5. Post-deploy Actions: If everything looks good, announce or continue development. If issues are found, fix in code and repeat the deployment (Vercel makes rollbacks easy too if needed).
   By following these instructions, deploying updates to Unchained should be a smooth, repeatable process. Vercel’s integration means we usually just focus on writing code and merging pull requests – the rest is automated. In case of any deployment-specific issues, consult Vercel’s documentation or their community forums, as they have extensive guides on common pitfalls for React/Vite apps. Overall, with proper setup, deploying Unchained is as simple as “git push” and letting Vercel handle the rest[36].

[1] [3] [27] unchained_style_guide.md
file://file-3KaHHkWYntS5GrivaL8LwG
[2] [4] [5] [6] [7] [8] [9] [10] [11] [12] [17] [18] [19] [20] [21] [22] [23] [24] [28] README.md
file://file-XAALWw3VtmH4pQgrDEMRCe
[13] [14] [33] Claude Code - AI Pair Programming Assistant | ClaudeCode.io
https://claudecode.io/
[15] GitHub - openai/codex: Lightweight coding agent that runs in your terminal
https://github.com/openai/codex
[16] slugify.js
file://file-UBX9GHo4NkWonUphuP1vys
[25] What is Prettier? · Prettier
https://prettier.io/docs/
[26] useFuseSearch.js
file://file-XzAVGDssbUMgNm15mQXNH4
[29] [34] [35] [36] [37] [38] How to Deploy a React Site with Vercel
https://vercel.com/guides/deploying-react-with-vercel
[30] [31] Best Practices I Learned for AI Assisted Coding | by Claire Longo | Medium
https://statistician-in-stilettos.medium.com/best-practices-i-learned-for-ai-assisted-coding-70ff7359d403
[32] Introducing Claude Sonnet 4.5 \ Anthropic
https://www.anthropic.com/news/claude-sonnet-4-5cel dashboard (one-time setup). 2. Trigger Deploy: Either push to the main branch if CI is configured, or run vercel --prod using the CLI. 3. Vercel Build: Vercel will detect the project and run the build (React app) and package serverless functions. No manual config needed in most cases[38]. 4. Verification: Once deployed, access the live URL. Test the application’s main functionalities (connect wallet, view events, etc.) on the live site. 5. Post-deploy Actions: If everything looks good, announce or continue development. If issues are found, fix in code and repeat the deployment (Vercel makes rollbacks easy too if needed).
By following these instructions, deploying updates to Unchained should be a smooth, repeatable process. Vercel’s integration means we usually just focus on writing code and merging pull requests – the rest is automated. In case of any deployment-specific issues, consult Vercel’s documentation or their community forums, as they have extensive guides on common pitfalls for React/Vite apps. Overall, with proper setup, deploying Unchained is as simple as “git push” and letting Vercel handle the rest[36].

[1] [3] [27] unchained_style_guide.md
file://file-3KaHHkWYntS5GrivaL8LwG
[2] [4] [5] [6] [7] [8] [9] [10] [11] [12] [17] [18] [19] [20] [21] [22] [23] [24] [28] README.md
file://file-XAALWw3VtmH4pQgrDEMRCe
[13] [14] [33] Claude Code - AI Pair Programming Assistant | ClaudeCode.io
https://claudecode.io/
[15] GitHub - openai/codex: Lightweight coding agent that runs in your terminal
https://github.com/openai/codex
[16] slugify.js
file://file-UBX9GHo4NkWonUphuP1vys
[25] What is Prettier? · Prettier
https://prettier.io/docs/
[26] useFuseSearch.js
file://file-XzAVGDssbUMgNm15mQXNH4
[29] [34] [35] [36] [37] [38] How to Deploy a React Site with Vercel
https://vercel.com/guides/deploying-react-with-vercel
[30] [31] Best Practices I Learned for AI Assisted Coding | by Claire Longo | Medium
https://statistician-in-stilettos.medium.com/best-practices-i-learned-for-ai-assisted-coding-70ff7359d403
[32] Introducing Claude Sonnet 4.5 \ Anthropic
https://www.anthropic.com/news/claude-sonnet-4-5
```
